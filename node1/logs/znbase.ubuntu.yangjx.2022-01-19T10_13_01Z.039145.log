I220119 10:13:01.394811 1 util/log/clog.go:1194  [config] file created at: 2022/01/19 10:13:01
I220119 10:13:01.394811 1 util/log/clog.go:1194  [config] running on machine: ubuntu
I220119 10:13:01.394811 1 util/log/clog.go:1194  [config] binary: ZNBaseDB OSS 4cd474b8 (x86_64-linux-gnu, built 2022/01/19 10:10:25, go1.14)
I220119 10:13:01.394811 1 util/log/clog.go:1194  [config] arguments: [./znbase start --insecure --store=./node1 --listen-addr=:23456 --http-addr=:8000 --join=:23456,:23457,:23458]
I220119 10:13:01.394811 1 util/log/clog.go:1194  line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=âœ“
I220119 10:13:01.394810 1 cli/start.go:1156  logging to directory /home/yangjx/go/src/github.com/znbasedb/znbase/node1/logs
W220119 10:13:01.395361 1 cli/start.go:1191  RUNNING IN INSECURE MODE!

- Your cluster is open for any client that can access <all your IP addresses>.
- Any user, even root, can log in without providing a password.
- Any user, connecting as root, can read or write any data in your cluster.
- There is no network encryption nor authentication, and thus no confidentiality.

Check out how to secure your cluster: official docs about version 4cd474b8
I220119 10:13:01.395586 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
W220119 10:13:01.395624 1 cli/start.go:1067  Using the default setting for --cache (128 MiB).
  A significantly larger value is usually needed for good performance.
  If you have a dedicated server a reasonable setting is --cache=.25 (976 MiB).
I220119 10:13:01.395711 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
W220119 10:13:01.395721 1 cli/start.go:1080  Using the default setting for --max-sql-memory (128 MiB).
  A significantly larger value is usually needed in production.
  If you have a dedicated server a reasonable setting is --max-sql-memory=.25 (976 MiB).
I220119 10:13:01.395804 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:13:01.395813 1 cli/start.go:1205  ZNBaseDB OSS 4cd474b8 (x86_64-linux-gnu, built 2022/01/19 10:10:25, go1.14)
I220119 10:13:01.408819 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:13:01.408849 1 server/config.go:400  system total memory: 3.8 GiB
I220119 10:13:01.408885 1 server/config.go:402  server configuration:
max offset             500000000
cache size             128 MiB
SQL memory pool size   128 MiB
scan interval          10m0s
scan min idle time     10ms
scan max idle time     1s
event log enabled      true
I220119 10:13:01.408902 1 cli/start.go:1045  using local environment variables: GODEBUG=cgocheck=0
I220119 10:13:01.408912 1 cli/start.go:1052  process identity: uid 1000 euid 1000 gid 1000 egid 1000
I220119 10:13:01.408926 1 cli/start.go:676  starting znbase node
I220119 10:13:01.410601 25 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-temp239861999"
I220119 10:13:01.427339 25 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-cursor-temp651455362"
I220119 10:13:01.453805 25 server/server.go:1008  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
W220119 10:13:01.454239 25 server/config_unix.go:92  soft open file descriptor limit 4096 is under the recommended limit 15000; this may decrease performance
please see official docs about version 4cd474b8 for more details
I220119 10:13:01.454290 25 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1"
I220119 10:13:01.707443 25 server/config.go:509  [n?] 1 storage engine initialized
I220119 10:13:01.707455 25 server/config.go:512  [n?] rocksdb cache size: 128 MiB
I220119 10:13:01.707460 25 server/config.go:512  [n?] store 0: rocksdb, max size 0 B, max open file limit 3840
W220119 10:13:01.711034 25 gossip/gossip.go:1508  [n?] no incoming or outgoing connections
I220119 10:13:01.712896 25 server/server.go:1058  [n?] Sleeping till wall time 1642587181712831175 to catches up to 1642587181952034848 to ensure monotonicity. Delta: 239.203673ms
I220119 10:13:01.713178 83 gossip/client.go:128  [n?] started gossip client to ubuntu:23457
I220119 10:13:01.714312 29 gossip/gossip.go:920  [n?] MaxPeers Recomputed as 3
I220119 10:13:01.714418 29 gossip/gossip.go:920  [n?] MaxPeers Recomputed as 3
I220119 10:13:01.952643 25 gossip/gossip.go:397  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"ubuntu:23456" > attrs:<> locality:<> ServerVersion:<major_val:19 minor_val:1 patch:0 unstable:10 > build_tag:"4cd474b8" started_at:1642587181952495637 location_name:<> 
I220119 10:13:01.952781 29 gossip/gossip.go:920  [n1] MaxPeers Recomputed as 3
I220119 10:13:01.982738 25 server/node.go:457  [n1] initialized store [n1,s1]: disk (capacity=78 GiB, available=35 GiB, used=30 MiB, logicalBytes=92 MiB), ranges=107, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=35172.00 p50=524279.00 p75=524293.00 p90=524301.00 pMax=56229172.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I220119 10:13:01.982831 25 storage/stores.go:238  [n1] read 2 node addresses from persistent storage
I220119 10:13:01.983054 25 server/node.go:695  [n1] connecting to gossip network to verify cluster ID...
I220119 10:13:01.983071 25 server/node.go:715  [n1] node connected via gossip and verified as part of cluster "3bbb8c74-c606-434f-b2eb-5e4523c470ba"
I220119 10:13:01.983124 25 server/node.go:538  [n1] node=1: started with [<no-attributes>=/home/yangjx/go/src/github.com/znbasedb/znbase/node1] engine(s) and attributes []
I220119 10:13:01.983322 25 server/status/recorder.go:610  [n1] available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:13:01.983386 25 server/server.go:1730  [n1] starting http server at [::]:8000 (use: ubuntu:8000)
I220119 10:13:01.983396 25 server/server.go:1732  [n1] starting grpc/postgres server at [::]:23456
I220119 10:13:01.983404 25 server/server.go:1733  [n1] advertising ZNBaseDB node at ubuntu:23456
W220119 10:13:40.134538 535 cli/start.go:666  The server appears to be unable to contact the other nodes in the cluster. Please try:

- starting the other nodes, if you haven't already;
- double-checking that the '--join' and '--listen'/'--advertise' flags are set up correctly;
- running the 'znbase init' command if you are trying to initialize a new cluster.

If problems persist, please see official docs about version 4cd474b8.
W220119 10:13:40.138536 95 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:13:40.138789 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 38.2s
W220119 10:13:40.138803 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted in distSender: context deadline exceeded
I220119 10:13:40.138962 475 server/status/runtime.go:500  [n1] runtime stats: 173 MiB RSS, 241 goroutines, 98 MiB/232 KiB/112 MiB GO alloc/idle/total, 14 MiB/20 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (7x), 1.0 MiB/1.0 MiB (r/w)net
W220119 10:13:40.139342 185 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:13:40.139898 104 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:13:40.140281 114 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:13:40.140323 103 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:13:40.140353 190 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:13:40.140390 96 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:13:40.140442 185 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:13:40.140446 110 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:13:40.141632 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:13:40.142081 507 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 tripped: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:13:40.142094 507 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerTripped
W220119 10:13:40.142106 507 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23458: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:13:40.142122 190 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:13:40.142133 110 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:13:40.142141 114 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:13:40.142309 87 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:13:40.142525 87 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:13:40.596518 128 storage/queue.go:468  [n1,s1,r2/1:/System/NodeLiveness{-Max}] rate limited in MaybeAdd (raftlog): throttled on async limiting semaphore
I220119 10:13:41.142908 946 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerReset
I220119 10:13:41.142920 946 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:13:41.985145 470 storage/store.go:4034  [n1,s1] sstables (read amplification = 1):
6 [ 19M 3 ]: 15M 2M[2]
I220119 10:13:41.985224 470 storage/store.go:4035  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0     19.1      0.10              0.00         1    0.096       0      0
  L6      3/0   19.12 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.2     79.4     45.5      0.05              0.04         1    0.049     34K   8446
 Sum      3/0   19.12 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   2.2     26.6     28.0      0.15              0.04         2    0.073     34K   8446
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   2.2     26.6     28.0      0.15              0.04         2    0.073     34K   8446

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Low      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0     79.4     45.5      0.05              0.04         1    0.049     34K   8446
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0     19.1      0.10              0.00         1    0.096       0      0
Uptime(secs): 40.5 total, 40.5 interval
Flush(GB): cumulative 0.002, interval 0.002
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.10 MB/s write, 0.00 GB read, 0.10 MB/s read, 0.1 seconds
Interval compaction: 0.00 GB write, 0.10 MB/s write, 0.00 GB read, 0.10 MB/s read, 0.1 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
I220119 10:13:42.588296 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:13:42.588482 79 storage/stores.go:257  [n1] wrote 2 node addresses to persistent storage
W220119 10:13:43.014985 534 storage/node_liveness.go:523  [n1,s1,r30/1:/Table/5{6-7}] slow heartbeat took 40.0s
E220119 10:13:43.015007 534 storage/replica_range_lease.go:292  [n1,s1,r30/1:/Table/5{6-7}] heartbeat failed on epoch increment
W220119 10:13:43.015099 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.9s
I220119 10:13:43.015114 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
I220119 10:13:44.841563 1124 storage/replica_raftstorage.go:817  [n1,s1,r4/1:/System{/tsd-tse}] applying RAFT snapshot at index 5015 (id=e0acdc0e, encoded size=13981756, 54 rocksdb batches, 0 log entries)
I220119 10:13:45.007177 1124 storage/replica_raftstorage.go:823  [n1,s1,r4/1:/System{/tsd-tse}] applied RAFT snapshot in 166ms [clear=0ms batch=100ms entries=0ms commit=65ms]
I220119 10:13:45.010997 1111 storage/replica_raftstorage.go:817  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] applying RAFT snapshot at index 4141 (id=ed9642c6, encoded size=118409, 1 rocksdb batches, 0 log entries)
I220119 10:13:45.026410 1111 storage/replica_raftstorage.go:823  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] applied RAFT snapshot in 15ms [clear=7ms batch=0ms entries=0ms commit=8ms]
I220119 10:13:45.030933 25 server/server.go:1802  [n1] done ensuring all necessary migrations have run
I220119 10:13:45.030948 25 server/server.go:1805  [n1] serving sql connections
I220119 10:13:45.031103 25 cli/start.go:813  [config] clusterID: 3bbb8c74-c606-434f-b2eb-5e4523c470ba
I220119 10:13:45.031168 25 cli/start.go:821  node startup completed:
ZNBaseDB node starting at 2022-01-19 10:13:45.031041419 +0000 UTC (took 43.6s)
build:               OSS 4cd474b8 @ 2022/01/19 10:10:25 (go1.14)
webui:               http://ubuntu:8000
sql:                 postgresql://root@ubuntu:23456?sslmode=disable
client flags:        ./znbase <client cmd> --host=ubuntu:23456 --insecure
logs:                /home/yangjx/go/src/github.com/znbasedb/znbase/node1/logs
temp dir:            /home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-temp239861999
external I/O path:   /home/yangjx/go/src/github.com/znbasedb/znbase/node1/extern
store[0]:            path=/home/yangjx/go/src/github.com/znbasedb/znbase/node1,state=ENABLE
storage engine:      rocksdb
status:              restarted pre-existing node
clusterID:           3bbb8c74-c606-434f-b2eb-5e4523c470ba
nodeID:              1
I220119 10:13:45.033480 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:13:45.033500 1185 security/audit/task/runner.go:216  [n1] audit_server_6221f23a-7910-11ec-8085-000c29793ffc monitor workers every 5 seconds
I220119 10:13:45.033513 1184 security/audit/task/runner.go:284  [n1] audit_server_6221f23a-7910-11ec-8085-000c29793ffc init, min:3, max:30
I220119 10:13:45.091265 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:13:45.100318 1137 sql/lease.go:2613  released orphaned table lease: {id:58 version:1 expiration:{Time:{wall:240859000 ext:63778182482 loc:<nil>}}}
I220119 10:13:45.100463 1136 sql/lease.go:2613  released orphaned table lease: {id:57 version:1 expiration:{Time:{wall:282828000 ext:63778182471 loc:<nil>}}}
I220119 10:13:45.121018 1135 sql/event_log.go:235  [n1] Event: "node_restart", target: 1, info: nodeID:1, lastUp:1642585400739658403, ClusterID:3bbb8c74-c606-434f-b2eb-5e4523c470ba
E220119 10:13:45.130239 1131 server/server.go:1869  [n1,client=127.0.0.1:60704] write tcp 127.0.0.1:23456->127.0.0.1:60704: write: broken pipe
I220119 10:13:45.186832 1133 sql/event_log.go:235  [n1] Event: "user_login", target: 1, info: User name:root  Client Info:127.0.0.1:60704  Login time:2022-01-19 10:13:45.126687292 +0000 UTC
I220119 10:13:45.188582 1134 sql/event_log.go:235  [n1] Event: "user_logout", target: 1, info: User name:root  Client Info:127.0.0.1:60704  Logout time:2022-01-19 10:13:45.130136941 +0000 UTC
I220119 10:13:46.198722 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:13:48.233500 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:13:50.141760 475 server/status/runtime.go:500  [n1] runtime stats: 273 MiB RSS, 217 goroutines, 98 MiB/78 MiB/194 MiB GO alloc/idle/total, 26 MiB/32 MiB CGO alloc/total, 1515.5 CGO/sec, 2.2/4.8 %(u/s)time, 0.0 %gc (2x), 2.5 MiB/2.5 MiB (r/w)net
I220119 10:13:50.911438 1135 sql/event_log.go:235  [n1] Event: "user_login", target: 1, info: User name:root  Client Info:127.0.0.1:60732  Login time:2022-01-19 10:13:50.887612706 +0000 UTC
I220119 10:13:50.920021 1133 sql/event_log.go:235  [n1] Event: "set_var", target: 0, info: User name:root SHOW SYNTAX:SET sql_safe_updates = true
I220119 10:13:52.099626 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:13:55.059682 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:13:55.109325 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:3}]}
I220119 10:14:00.143100 475 server/status/runtime.go:500  [n1] runtime stats: 259 MiB RSS, 219 goroutines, 120 MiB/57 MiB/194 MiB GO alloc/idle/total, 26 MiB/33 MiB CGO alloc/total, 64.9 CGO/sec, 0.9/2.0 %(u/s)time, 0.0 %gc (0x), 566 KiB/566 KiB (r/w)net
I220119 10:14:08.956473 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:14:08.956747 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  3: ubuntu:23458 (28s: infos 71/96 sent/received, bytes 19182B/17374B sent/received)
gossip server (0/3 cur/max conns, infos 84/185 sent/received, bytes 22124B/74722B sent/received)
gossip connectivity
W220119 10:14:08.959818 718 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:08.959961 722 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:08.960003 722 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:08.960062 759 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:08.960193 684 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:08.960217 707 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:08.960414 688 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:08.960440 707 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:08.963348 658 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:08.963658 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:107}]}
W220119 10:14:08.963873 688 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:08.963911 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
I220119 10:14:13.519456 1573 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:14:08.963659 712 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:13.525854 712 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:14:13.527050 124 storage/store.go:3503  [n1,s1,r78/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 4.6s [applied=2, batches=2, state_assertions=1]
I220119 10:14:18.127095 1628 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:14:18.127535 475 server/status/runtime.go:500  [n1] runtime stats: 248 MiB RSS, 232 goroutines, 129 MiB/48 MiB/194 MiB GO alloc/idle/total, 26 MiB/33 MiB CGO alloc/total, 5.7 CGO/sec, 0.2/0.1 %(u/s)time, 0.0 %gc (0x), 711 KiB/711 KiB (r/w)net
W220119 10:14:18.128068 126 storage/store.go:3503  [n1,s1,r13/1:/Table/1{7-8}] handle raft ready: 9.2s [applied=2, batches=2, state_assertions=1]
W220119 10:14:18.128219 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.6s
W220119 10:14:18.128227 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:14:18.129145 145 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 9.2s [applied=0, batches=0, state_assertions=0]
W220119 10:14:18.129303 134 storage/store.go:3503  [n1,s1,r73/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 9.2s [applied=0, batches=0, state_assertions=0]
W220119 10:14:18.129353 136 storage/store.go:3503  [n1,s1,r12/1:/Table/1{6-7}] handle raft ready: 4.6s [applied=0, batches=0, state_assertions=0]
I220119 10:14:19.782033 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:14:19.785462 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:14:19.785716 143 storage/store.go:3503  [n1,s1,r86/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 1.6s [applied=2, batches=2, state_assertions=1]
W220119 10:14:19.785907 141 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.6s [applied=9, batches=3, state_assertions=1]
W220119 10:14:21.469839 140 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W220119 10:14:21.472903 128 storage/store.go:3503  [n1,s1,r12/1:/Table/1{6-7}] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
W220119 10:14:21.473352 131 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.7s [applied=8, batches=5, state_assertions=2]
W220119 10:14:21.473407 125 storage/store.go:3503  [n1,s1,r73/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 1.7s [applied=1, batches=1, state_assertions=0]
I220119 10:14:21.474252 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:14:21.474486 1601 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:14:22.925075 147 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=0]
W220119 10:14:22.925951 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.8s
W220119 10:14:22.925972 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:14:22.927279 1609 storage/node_liveness.go:523  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 9.4s
I220119 10:14:22.927399 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
W220119 10:14:22.929003 126 storage/store.go:3503  [n1,s1,r33/1:/Table/58{-/1/-9223â€¦}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:14:22.929082 135 storage/store.go:3503  [n1,s1,r49/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:14:24.389151 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:14:24.391433 143 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
I220119 10:14:24.423884 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
W220119 10:14:25.844217 129 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
W220119 10:14:25.864381 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:14:28.533821 475 server/status/runtime.go:500  [n1] runtime stats: 252 MiB RSS, 232 goroutines, 146 MiB/30 MiB/194 MiB GO alloc/idle/total, 34 MiB/41 MiB CGO alloc/total, 88.6 CGO/sec, 1.0/0.9 %(u/s)time, 0.0 %gc (0x), 1.7 MiB/1.7 MiB (r/w)net
I220119 10:14:30.004073 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:14:40.692757 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:14:40.694998 475 server/status/runtime.go:500  [n1] runtime stats: 238 MiB RSS, 231 goroutines, 146 MiB/30 MiB/194 MiB GO alloc/idle/total, 34 MiB/41 MiB CGO alloc/total, 15.9 CGO/sec, 0.3/0.2 %(u/s)time, 0.0 %gc (1x), 807 KiB/807 KiB (r/w)net
W220119 10:14:40.696663 1534 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:40.696969 1541 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:40.697034 1622 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:40.697119 1620 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:40.697205 1579 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:40.698034 1543 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:40.698074 1543 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:40.698095 1622 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:40.698100 1878 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:14:40.698137 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:14:40.698190 1584 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:40.699012 1579 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:40.699106 1556 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:14:40.699136 1598 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:40.699441 1556 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:14:40.700243 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:14:40.700527 1584 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:14:40.714789 1971 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:14:40.733440 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.476395007e+09}]}
I220119 10:14:40.741190 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
I220119 10:14:41.424326 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:14:42.510330 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:14:45.049276 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1} {StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.476395007e+09}]}
I220119 10:14:52.482794 475 server/status/runtime.go:500  [n1] runtime stats: 233 MiB RSS, 223 goroutines, 98 MiB/72 MiB/194 MiB GO alloc/idle/total, 35 MiB/42 MiB CGO alloc/total, 72.9 CGO/sec, 1.3/1.3 %(u/s)time, 0.0 %gc (0x), 841 KiB/841 KiB (r/w)net
I220119 10:14:52.486453 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:14:59.113966 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:14:59.114196 2187 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:14:59.115103 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:14:59.117627 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:14:59.117645 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.6s
W220119 10:14:59.117655 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:14:59.118021 1962 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:14:59.118451 134 storage/store.go:3503  [n1,s1,r15/1:/Table/{19-20}] handle raft ready: 6.6s [applied=2, batches=2, state_assertions=1]
W220119 10:14:59.118763 140 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 6.6s [applied=1, batches=1, state_assertions=1]
W220119 10:15:04.267579 1946 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:04.268726 1826 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:15:04.268969 1884 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:04.269044 1957 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:04.269238 1884 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:15:04.269356 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:15:04.269377 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.2s
W220119 10:15:04.269392 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:15:04.269779 126 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 11.8s [applied=2, batches=1, state_assertions=0]
I220119 10:15:04.270158 2175 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
I220119 10:15:04.270173 2175 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:15:04.270206 2175 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
W220119 10:15:04.270422 1946 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:15:04.271151 1961 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
I220119 10:15:04.271957 2166 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:15:04.784303 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  3: ubuntu:23458 (24s: infos 47/48 sent/received, bytes 8675B/8335B sent/received)
gossip server (1/3 cur/max conns, infos 276/508 sent/received, bytes 96920B/126800B sent/received)
  2: ubuntu:23457 (24s)
gossip connectivity
  n1 -> n3;
W220119 10:15:04.784378 1957 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:15:04.784668 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:15:04.785233 1973 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:04.785292 1877 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:15:04.786247 1973 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:15:04.786440 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:15:04.786537 142 storage/store.go:3503  [n1,s1,r94/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
I220119 10:15:05.758298 475 server/status/runtime.go:500  [n1] runtime stats: 233 MiB RSS, 198 goroutines, 131 MiB/44 MiB/194 MiB GO alloc/idle/total, 35 MiB/42 MiB CGO alloc/total, 6.1 CGO/sec, 0.0/0.2 %(u/s)time, 0.0 %gc (0x), 1018 KiB/1018 KiB (r/w)net
W220119 10:15:05.758477 146 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:15:05.760277 126 storage/store.go:3503  [n1,s1,r90/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 1.5s [applied=1, batches=1, state_assertions=1]
I220119 10:15:05.762092 2194 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:15:05.762124 2335 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:15:06.386398 139 storage/store.go:3503  [n1,s1,r33/1:/Table/58{-/1/-9223â€¦}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:15:06.386439 135 storage/store.go:3503  [n1,s1,r91/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:15:06.386668 143 storage/store.go:3503  [n1,s1,r94/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.6s [applied=2, batches=2, state_assertions=1]
W220119 10:15:06.386801 127 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=11, batches=5, state_assertions=2]
W220119 10:15:06.386834 138 storage/store.go:3503  [n1,s1,r49/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:15:06.386855 145 storage/store.go:3503  [n1,s1,r28/1:/Table/5{1-3}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:15:07.657012 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.006632959e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
I220119 10:15:07.661221 2173 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:15:07.667900 134 storage/engine/rocksdb.go:2234  batch [753/84937/2] commit took 723.731656ms (>= warning threshold 500ms)
W220119 10:15:07.667980 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=1, batches=1, state_assertions=0]
W220119 10:15:14.372124 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:15:14.372297 2372 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:15:14.376737 134 storage/engine/rocksdb.go:2234  batch [1507/169839/3] commit took 6.683552713s (>= warning threshold 500ms)
I220119 10:15:14.377103 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:15:14.377114 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 10.1s
W220119 10:15:14.377124 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:15:14.377335 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 6.7s [applied=5, batches=1, state_assertions=0]
W220119 10:15:15.797104 130 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.4s [applied=1, batches=1, state_assertions=0]
I220119 10:15:15.798635 475 server/status/runtime.go:500  [n1] runtime stats: 235 MiB RSS, 226 goroutines, 131 MiB/44 MiB/194 MiB GO alloc/idle/total, 35 MiB/42 MiB CGO alloc/total, 31.3 CGO/sec, 0.4/0.4 %(u/s)time, 0.0 %gc (0x), 1.5 MiB/1.5 MiB (r/w)net
W220119 10:15:18.552236 134 storage/engine/rocksdb.go:2234  batch [2257/254631/4] commit took 2.752389003s (>= warning threshold 500ms)
W220119 10:15:18.552283 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 4.2s [applied=4, batches=1, state_assertions=0]
W220119 10:15:18.552335 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.2s
I220119 10:15:18.554104 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:15:18.554560 146 storage/store.go:3503  [n1,s1,r49/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 4.2s [applied=1, batches=1, state_assertions=0]
W220119 10:15:18.554563 135 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 4.2s [applied=7, batches=7, state_assertions=4]
W220119 10:15:18.554802 137 storage/store.go:3503  [n1,s1,r47/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 4.2s [applied=2, batches=2, state_assertions=1]
W220119 10:15:18.555027 138 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.2s [applied=6, batches=3, state_assertions=1]
W220119 10:15:18.558144 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.006632959e+09}]}
I220119 10:15:18.572382 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:15:40.169589 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:15:40.170542 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:15:40.170559 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 21.6s
W220119 10:15:40.170568 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:15:49.215505 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:15:49.215641 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:15:49.219681 124 storage/store.go:3503  [n1,s1,r61/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 33.4s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.219751 127 storage/store.go:3503  [n1,s1,r81/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 33.4s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.219780 130 storage/store.go:3503  [n1,s1,r94/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 33.4s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.219812 132 storage/store.go:3503  [n1,s1,r15/1:/Table/{19-20}] handle raft ready: 33.4s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.219843 142 storage/store.go:3503  [n1,s1,r90/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 33.4s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.221141 2335 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I220119 10:15:49.221515 475 server/status/runtime.go:500  [n1] runtime stats: 233 MiB RSS, 262 goroutines, 170 MiB/6.4 MiB/194 MiB GO alloc/idle/total, 34 MiB/43 MiB CGO alloc/total, 6.2 CGO/sec, 0.1/0.0 %(u/s)time, 0.0 %gc (0x), 1.5 MiB/1.5 MiB (r/w)net
W220119 10:15:49.221672 2271 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:49.221763 2333 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:15:49.221795 2238 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:15:49.221950 2265 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:49.222321 2260 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:49.222354 2306 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:15:49.222796 2302 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:15:49.222908 147 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 30.7s [applied=9, batches=1, state_assertions=0]
W220119 10:15:49.223026 129 storage/store.go:3503  [n1,s1,r104/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 30.7s [applied=0, batches=0, state_assertions=0]
W220119 10:15:49.223156 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 9.1s
W220119 10:15:49.223165 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted in distSender: context deadline exceeded
W220119 10:15:49.224562 2271 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:15:59.816525 125 storage/store.go:3503  [n1,s1,r8/1:/Table/1{2-3}] handle raft ready: 10.6s [applied=0, batches=0, state_assertions=0]
W220119 10:15:59.818623 137 storage/store.go:3503  [n1,s1,r47/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 41.3s [applied=0, batches=0, state_assertions=0]
W220119 10:15:59.818966 145 storage/store.go:3503  [n1,s1,r92/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 44.0s [applied=2, batches=2, state_assertions=1]
W220119 10:15:59.819357 131 storage/store.go:3503  [n1,s1,r66/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 41.3s [applied=2, batches=2, state_assertions=1]
W220119 10:16:11.752092 2260 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:16:11.752103 2306 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:16:11.752133 153 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:16:11.752171 146 storage/store.go:3503  [n1,s1,r103/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 53.2s [applied=2, batches=2, state_assertions=1]
W220119 10:16:11.752178 2124 storage/replica_write.go:191  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 72.64s for proposing command RequestLease [/Min,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/1

and the following Raft status: {"id":"1","term":13,"vote":"0","commit":2914,"lead":"2","raftState":"StateFollower","applied":2912,"progress":{},"leadtransferee":"0"}
W220119 10:16:11.752346 155 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
W220119 10:16:11.752370 135 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 53.2s [applied=2, batches=2, state_assertions=1]
W220119 10:16:11.752716 129 storage/store.go:3503  [n1,s1,r104/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 22.5s [applied=1, batches=1, state_assertions=0]
W220119 10:16:11.752830 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:16:11.752848 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (2/3 cur/max conns)
  2: ubuntu:23457 (1m7s: infos 16/65 sent/received, bytes 3592B/9502B sent/received)
  3: ubuntu:23458 (57s: infos 12/26 sent/received, bytes 1852B/3872B sent/received)
gossip server (0/3 cur/max conns, infos 310/654 sent/received, bytes 105657B/149658B sent/received)
gossip connectivity
I220119 10:16:11.752983 2412 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:16:11.753402 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:16:11.753414 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 22.5s
W220119 10:16:11.753423 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:16:11.753527 2429 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:16:11.754083 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:16:11.754173 122 storage/store.go:3503  [n1,s1,r104/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 11.9s [applied=0, batches=0, state_assertions=0]
W220119 10:16:11.755967 134 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 22.5s [applied=0, batches=0, state_assertions=0]
W220119 10:16:11.756326 147 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 22.5s [applied=0, batches=0, state_assertions=0]
W220119 10:16:11.756388 2247 storage/replica_write.go:191  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 67.48s for proposing command RequestLease [/System/NodeLiveness,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/2

and the following Raft status: {"id":"1","term":15,"vote":"0","commit":10097,"lead":"3","raftState":"StateFollower","applied":10093,"progress":{},"leadtransferee":"0"}
W220119 10:18:19.100762 138 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 180.5s [applied=4, batches=1, state_assertions=0]
I220119 10:18:19.101353 475 server/status/runtime.go:500  [n1] runtime stats: 236 MiB RSS, 186 goroutines, 176 MiB/880 KiB/194 MiB GO alloc/idle/total, 34 MiB/43 MiB CGO alloc/total, 0.8 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (0x), 3.5 MiB/3.5 MiB (r/w)net
W220119 10:18:19.101495 2595 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing dial tcp 127.0.1.1:23458: i/o timeout". Reconnecting...
W220119 10:18:19.101524 2595 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:18:19.101643 2595 vendor/google.golang.org/grpc/clientconn.go:953  Failed to dial ubuntu:23458: context canceled; please retry.
I220119 10:18:19.101986 2581 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: not yet heartbeated
I220119 10:18:19.102001 2581 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:18:19.102009 2581 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: not yet heartbeated
W220119 10:18:19.103764 2265 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:18:19.103915 136 storage/engine/rocksdb.go:2234  batch [1516/170022/4] commit took 2m7.3509602s (>= warning threshold 500ms)
W220119 10:18:19.104086 136 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 180.6s [applied=4, batches=1, state_assertions=0]
W220119 10:18:19.105175 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:18:28.690923 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:18:30.307587 2561 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:18:30.307598 2561 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:18:30.307609 2561 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:18:30.308016 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 138.6s
W220119 10:18:30.308023 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
I220119 10:18:30.309673 2428 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:18:30.309735 2428 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:18:30.309747 2428 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:18:30.355377 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: show-version: operation "show cluster setting version" timed out after 2m0s
W220119 10:18:30.358898 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:18:30.450665 2605 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing dial tcp: i/o timeout". Reconnecting...
W220119 10:18:30.450736 2605 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:18:30.456966 2605 vendor/google.golang.org/grpc/clientconn.go:953  Failed to dial ubuntu:23458: context canceled; please retry.
W220119 10:18:36.426386 138 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 17.3s [applied=0, batches=0, state_assertions=0]
W220119 10:18:36.426434 142 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 7.7s [applied=0, batches=0, state_assertions=0]
I220119 10:18:40.756545 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:18:55.767130 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:18:55.767876 2622 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing dial tcp: i/o timeout". Reconnecting...
W220119 10:18:55.767928 2622 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:18:57.410145 2622 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:19:08.603460 2622 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:19:08.603573 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:19:08.605326 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:19:08.608496 2622 vendor/google.golang.org/grpc/clientconn.go:953  Failed to dial ubuntu:23458: context canceled; please retry.
I220119 10:19:08.608730 2576 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:19:08.608888 2615 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:19:08.610274 475 server/status/runtime.go:500  [n1] runtime stats: 212 MiB RSS, 269 goroutines, 178 MiB/3.4 MiB/198 MiB GO alloc/idle/total, 34 MiB/43 MiB CGO alloc/total, 1.4 CGO/sec, 0.1/0.1 %(u/s)time, 0.0 %gc (0x), 2.4 MiB/2.4 MiB (r/w)net
I220119 10:19:08.610764 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:19:08.610777 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 38.2s
W220119 10:19:08.610787 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:19:08.614800 2599 vendor/google.golang.org/grpc/clientconn.go:1411  grpc: addrConn.transportMonitor didn't get server preface after waiting. Closing the new transport now.
W220119 10:19:08.614924 2599 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:19:08.615003 2611 vendor/google.golang.org/grpc/clientconn.go:1411  grpc: addrConn.transportMonitor didn't get server preface after waiting. Closing the new transport now.
W220119 10:19:08.615065 2599 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:19:08.615077 2611 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:19:08.615286 2209 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:19:08.615293 2209 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:19:08.615299 2209 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:19:08.615444 2427 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:19:08.615447 2427 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
W220119 10:19:08.615622 2611 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:19:08.617030 476 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
I220119 10:19:08.617031 2691 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:19:21.306949 2628 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:19:21.307913 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:19:21.308645 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:19:21.308676 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:19:21.312575 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2} {StoreID:1 Category:METRICS Description:requests.slow.raft Value:2} {StoreID:1 Category:METRICS Description:requests.slow.lease Value:2}]}
W220119 10:19:21.314793 2974 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:19:21.315387 3076 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:19:21.315415 3076 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:19:21.315638 3282 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:19:21.315712 3282 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:19:21.316670 2974 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:19:21.317965 54 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:19:21.319224 2691 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:19:21.319822 139 storage/store.go:3503  [n1,s1,r29/1:/Table/5{3-5}] handle raft ready: 12.7s [applied=2, batches=2, state_assertions=1]
I220119 10:19:21.320134 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 310/654 sent/received, bytes 105657B/149708B sent/received)
I220119 10:19:21.323833 475 server/status/runtime.go:500  [n1] runtime stats: 213 MiB RSS, 194 goroutines, 178 MiB/3.4 MiB/198 MiB GO alloc/idle/total, 34 MiB/43 MiB CGO alloc/total, 79.4 CGO/sec, 0.1/0.3 %(u/s)time, 0.0 %gc (1x), 412 KiB/412 KiB (r/w)net
I220119 10:19:21.324560 2978 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:19:21.324641 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:19:21.324652 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:19:21.328232 3356 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:19:21.378062 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:5} {StoreID:1 Category:METRICS Description:requests.slow.lease Value:3} {StoreID:1 Category:METRICS Description:requests.slow.raft Value:2}]}
I220119 10:19:22.377309 3496 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:19:22.790115 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:19:22.942602 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:19:23.581048 2247 storage/replica_write.go:208  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow command RequestLease [/System/NodeLiveness,/Min) finished after 259.31s with error cannot replace lease repl=(n3,s3):3 seq=11 start=1642587249.016131771,1 exp=1642587568.516144728,0 pro=1642587559.516150338,0 with repl=(n1,s1):1 seq=12 start=1642587298.516176778,1 exp=1642587313.271500734,0 pro=1642587304.271511234,0: proposed under invalid lease
I220119 10:19:23.581297 155 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 4m19.309764836s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; current lease is repl=(n3,s3):3 seq=11 start=1642587249.016131771,1 exp=1642587568.516144728,0 pro=1642587559.516150338,0 after 1 attempts
W220119 10:19:23.588319 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.3s
I220119 10:19:24.582479 2124 storage/replica_write.go:208  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow command RequestLease [/Min,/Min) finished after 265.47s with error cannot replace lease repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587570.557075920,0 pro=1642587561.557081601,0 with repl=(n1,s1):1 seq=13 start=1642587296.057430705,1 exp=1642587308.115231539,0 pro=1642587299.115236539,0: proposed under invalid lease
I220119 10:19:24.582556 153 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 4m25.467301211s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587570.557075920,0 pro=1642587561.557081601,0 after 1 attempts
I220119 10:19:24.582957 2628 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m5.478532444s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587570.557075920,0 pro=1642587561.557081601,0 after 1 attempts
I220119 10:19:24.637717 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:19:25.706570 3603 storage/replica_raftstorage.go:817  [n1,s1,r4/1:/System{/tsd-tse}] applying RAFT snapshot at index 5172 (id=ea50b0be, encoded size=14537159, 56 rocksdb batches, 0 log entries)
W220119 10:19:25.707962 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:19:25.821995 3603 storage/replica_raftstorage.go:823  [n1,s1,r4/1:/System/tsd{-/cr.stoâ€¦}] applied RAFT snapshot in 115ms [clear=2ms batch=55ms entries=0ms commit=58ms]
I220119 10:19:26.580656 3672 storage/replica_raftstorage.go:817  [n1,s1,r118/1:{-}] applying RAFT snapshot at index 49 (id=2a76d8c1, encoded size=1138, 1 rocksdb batches, 0 log entries)
I220119 10:19:26.582173 3672 storage/replica_raftstorage.go:823  [n1,s1,r118/1:/System{/tsd/cr.sâ€¦-tse}] applied RAFT snapshot in 1ms [clear=0ms batch=0ms entries=0ms commit=1ms]
W220119 10:19:29.333130 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:19:31.308347 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:19:31.327277 475 server/status/runtime.go:500  [n1] runtime stats: 284 MiB RSS, 220 goroutines, 108 MiB/67 MiB/198 MiB GO alloc/idle/total, 50 MiB/61 MiB CGO alloc/total, 286.1 CGO/sec, 2.0/4.1 %(u/s)time, 0.0 %gc (1x), 2.8 MiB/2.8 MiB (r/w)net
W220119 10:19:35.647937 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:19:43.868199 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:19:43.875103 475 server/status/runtime.go:500  [n1] runtime stats: 277 MiB RSS, 231 goroutines, 89 MiB/109 MiB/223 MiB GO alloc/idle/total, 58 MiB/69 MiB CGO alloc/total, 35.1 CGO/sec, 0.8/2.2 %(u/s)time, 0.0 %gc (1x), 578 KiB/578 KiB (r/w)net
W220119 10:19:49.660286 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:20:44.822552 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:21:00.210297 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:21:00.210722 3824 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
I220119 10:21:00.210861 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:21:00.210903 3824 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m10.547673492s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
I220119 10:21:00.211104 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  2: ubuntu:23457 (1m39s: infos 51/101 sent/received, bytes 9202B/14317B sent/received)
gossip server (0/3 cur/max conns, infos 361/755 sent/received, bytes 114859B/164025B sent/received)
gossip connectivity
  n1 -> n2;
I220119 10:21:00.211769 475 server/status/runtime.go:500  [n1] runtime stats: 234 MiB RSS, 232 goroutines, 89 MiB/109 MiB/223 MiB GO alloc/idle/total, 58 MiB/69 MiB CGO alloc/total, 1.9 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (0x), 1.9 MiB/1.9 MiB (r/w)net
W220119 10:21:00.211814 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:21:00.211976 482 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
W220119 10:21:00.211987 3823 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
I220119 10:21:00.211997 482 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m10.552238666s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
I220119 10:21:00.212023 3823 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m10.550739168s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:21:00.212069 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 70.6s
W220119 10:21:00.212075 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:21:00.212119 3822 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
I220119 10:21:00.212126 3822 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m10.549445939s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:21:00.212777 3360 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:21:00.212956 3898 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:21:00.213282 131 storage/engine/rocksdb.go:2234  batch [1506/169755/4] commit took 1m10.543602669s (>= warning threshold 500ms)
W220119 10:21:00.213449 131 storage/store.go:3503  [n1,s1,r4/1:/System/tsd{-/cr.stoâ€¦}] handle raft ready: 70.6s [applied=4, batches=1, state_assertions=0]
W220119 10:21:00.213921 3370 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:21:00.214563 3360 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:00.217208 142 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 70.5s [applied=1, batches=1, state_assertions=0]
W220119 10:21:00.218203 3930 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:21:00.218232 3496 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:21:00.218978 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:21:00.225862 3474 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:00.225952 3469 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:00.225991 3434 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:00.226017 3387 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:00.226084 3474 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:00.226105 3469 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:00.226121 3434 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:00.226156 3387 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:00.296239 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:21:00.396105 130 storage/store.go:2590  [n1,s1,r4/1:/System/tsd{-/cr.stoâ€¦}] removing replica r118/1
I220119 10:21:01.213890 4191 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:21:01.983530 471 gossip/gossip.go:562  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  2: ubuntu:23457 (1s: infos 6/18 sent/received, bytes 981B/2233B sent/received)
gossip server (0/3 cur/max conns, infos 368/796 sent/received, bytes 116294B/169220B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n2; n2 -> n3;
I220119 10:21:02.283493 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:21:03.212828 3895 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:21:04.712739 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.5s
W220119 10:21:04.712759 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
I220119 10:21:05.012102 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
W220119 10:21:05.043215 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:21:10.211389 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:21:10.214663 475 server/status/runtime.go:500  [n1] runtime stats: 245 MiB RSS, 213 goroutines, 101 MiB/98 MiB/223 MiB GO alloc/idle/total, 58 MiB/70 MiB CGO alloc/total, 174.7 CGO/sec, 2.5/4.4 %(u/s)time, 0.0 %gc (0x), 1.0 MiB/1.0 MiB (r/w)net
I220119 10:21:15.397368 161 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /System/tsd/cr.store.valcount/3/10s/2022-01-19T10:00:00Z - /System/"tse" that contains live data
I220119 10:21:15.398483 161 storage/compactor/compactor.go:329  [n1,s1,compactor] purging suggested compaction for range /Table/57 - /Max that contains live data
W220119 10:21:16.058692 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:21:20.211973 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:21:20.216765 475 server/status/runtime.go:500  [n1] runtime stats: 247 MiB RSS, 213 goroutines, 160 MiB/31 MiB/212 MiB GO alloc/idle/total, 58 MiB/70 MiB CGO alloc/total, 39.9 CGO/sec, 0.8/1.6 %(u/s)time, 0.0 %gc (1x), 424 KiB/424 KiB (r/w)net
W220119 10:21:29.109957 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:21:29.110153 4612 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:21:29.110298 139 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 4.5s [applied=2, batches=2, state_assertions=1]
I220119 10:21:30.806681 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:21:30.808292 475 server/status/runtime.go:500  [n1] runtime stats: 248 MiB RSS, 218 goroutines, 97 MiB/94 MiB/217 MiB GO alloc/idle/total, 59 MiB/71 MiB CGO alloc/total, 19.0 CGO/sec, 0.2/0.3 %(u/s)time, 0.0 %gc (0x), 1.0 MiB/1.0 MiB (r/w)net
W220119 10:21:30.810088 134 storage/engine/rocksdb.go:2234  batch [1507/171355/4] commit took 1.679492366s (>= warning threshold 500ms)
W220119 10:21:30.810229 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.7s [applied=4, batches=1, state_assertions=0]
W220119 10:21:34.186872 138 storage/store.go:3503  [n1,s1,r85/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:21:34.186898 141 storage/store.go:3503  [n1,s1,r106/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:21:34.186908 143 storage/store.go:3503  [n1,s1,r58/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:21:34.186915 147 storage/store.go:3503  [n1,s1,r53/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:21:34.187217 145 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 5.1s [applied=2, batches=1, state_assertions=0]
I220119 10:21:34.187351 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:21:34.188001 139 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 5.1s [applied=1, batches=1, state_assertions=1]
W220119 10:21:34.188469 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 3.4s
W220119 10:21:35.711425 145 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:21:35.713340 116 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:21:35.718457 134 storage/engine/rocksdb.go:2234  batch [753/85689/2] commit took 1.529440129s (>= warning threshold 500ms)
W220119 10:21:35.718595 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 4.9s [applied=1, batches=1, state_assertions=0]
W220119 10:21:35.721986 144 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.9s [applied=5, batches=3, state_assertions=1]
W220119 10:21:43.675929 142 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 8.0s [applied=0, batches=0, state_assertions=0]
W220119 10:21:43.676360 133 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 8.0s [applied=0, batches=0, state_assertions=0]
W220119 10:21:43.676407 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:21:43.676419 475 server/status/runtime.go:500  [n1] runtime stats: 248 MiB RSS, 219 goroutines, 112 MiB/80 MiB/217 MiB GO alloc/idle/total, 58 MiB/69 MiB CGO alloc/total, 12.4 CGO/sec, 0.2/0.1 %(u/s)time, 0.0 %gc (0x), 484 KiB/484 KiB (r/w)net
I220119 10:21:43.676954 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:21:43.676961 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 8.0s
W220119 10:21:43.676969 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:21:43.677176 144 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 8.0s [applied=4, batches=3, state_assertions=1]
W220119 10:21:43.679113 4028 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:21:43.680102 4675 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
I220119 10:21:43.680113 4675 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:21:43.680124 4675 rpc/nodedialer/nodedialer.go:149  [intExec=adopt-job,n1,txn=7921fe55] unable to connect to n2: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
W220119 10:21:43.680562 4180 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:43.680591 4221 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:21:43.681780 4180 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:43.682066 4211 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:43.682124 4212 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I220119 10:21:57.076128 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:21:57.076733 4211 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:21:57.077078 4213 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:21:57.077256 4196 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:21:57.077569 4196 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:21:57.077626 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
W220119 10:21:57.078710 4740 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:21:57.079087 129 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 13.4s [applied=2, batches=1, state_assertions=0]
W220119 10:21:57.081262 4231 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:21:57.081322 4028 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:22:03.002197 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:22:03.005156 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:22:03.005870 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 200 goroutines, 112 MiB/80 MiB/217 MiB GO alloc/idle/total, 58 MiB/69 MiB CGO alloc/total, 4.7 CGO/sec, 0.0/0.1 %(u/s)time, 0.0 %gc (0x), 547 KiB/547 KiB (r/w)net
I220119 10:22:03.007783 13 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
I220119 10:22:03.010314 4843 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:22:03.010460 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  0: ubuntu:23457 (0s: infos 0/0 sent/received, bytes 83B/0B sent/received)
gossip server (0/3 cur/max conns, infos 429/1004 sent/received, bytes 125761B/196329B sent/received)
gossip connectivity
I220119 10:22:03.011192 4689 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:22:03.011196 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:22:03.011258 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:22:03.011272 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 19.3s
W220119 10:22:03.011282 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
E220119 10:22:03.011301 4584 storage/replica_range_lease.go:292  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] heartbeat failed on epoch increment
W220119 10:22:03.011407 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:22:03.166200 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:22:05.379570 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:22:06.011639 4585 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:22:06.387012 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 3.4s
W220119 10:22:06.387062 4586 storage/node_liveness.go:523  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] slow heartbeat took 3.4s
W220119 10:22:06.402063 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:6.174015487e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
I220119 10:22:28.479621 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 2 not running (UNAVAILABLE), cannot determine version
W220119 10:22:28.479860 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:22:28.480069 4979 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:22:28.484319 4803 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:28.484351 4665 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:28.484532 4852 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:28.485215 4803 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:28.486053 4741 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I220119 10:22:28.486150 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:22:28.487414 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 199 goroutines, 164 MiB/32 MiB/217 MiB GO alloc/idle/total, 66 MiB/78 MiB CGO alloc/total, 36.7 CGO/sec, 0.5/0.9 %(u/s)time, 0.0 %gc (0x), 1.5 MiB/1.5 MiB (r/w)net
W220119 10:22:28.488337 5000 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:22:28.489388 4824 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:22:28.490604 4757 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:28.490838 4733 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:28.490887 4733 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:28.490896 4757 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:28.491525 4786 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:28.491561 4786 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
E220119 10:22:28.492572 1164 jobs/job_scheduler.go:183  [n1] error executing schedules: rpc error: code = Unavailable desc = transport is closing
find-scheduled-jobs
github.com/znbasedb/znbase/pkg/sql.(*internalExecutorImpl).execInternal.func1
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/sql/internal.go:543
github.com/znbasedb/znbase/pkg/sql.(*internalExecutorImpl).execInternal
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/sql/internal.go:646
github.com/znbasedb/znbase/pkg/sql.(*internalExecutorImpl).queryInternal
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/sql/internal.go:269
github.com/znbasedb/znbase/pkg/sql.(*InternalExecutor).QueryWithCols
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/sql/internal.go:253
github.com/znbasedb/znbase/pkg/jobs.(*jobScheduler).executeSchedules
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/jobs/job_scheduler.go:143
github.com/znbasedb/znbase/pkg/jobs.(*jobScheduler).runDaemon.func1.1
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/jobs/job_scheduler.go:179
github.com/znbasedb/znbase/pkg/internal/client.(*DB).Txn.func1
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/internal/client/db.go:669
github.com/znbasedb/znbase/pkg/internal/client.(*Txn).exec
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/internal/client/txn.go:849
github.com/znbasedb/znbase/pkg/internal/client.(*DB).Txn
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/internal/client/db.go:668
github.com/znbasedb/znbase/pkg/jobs.(*jobScheduler).runDaemon.func1
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/jobs/job_scheduler.go:178
github.com/znbasedb/znbase/pkg/util/stop.(*Stopper).RunWorker.func1
	/home/yangjx/go/src/github.com/znbasedb/znbase/pkg/util/stop/stopper.go:201
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1373
W220119 10:22:28.501512 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:6.174015487e+09}]}
I220119 10:22:28.521480 4671 sql/lease.go:2545  refreshing table: 57 lease failed: result is ambiguous (error=rpc error: code = Unavailable desc = transport is closing [exhausted])
I220119 10:22:29.480860 5156 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:22:29.487392 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 1.0s
I220119 10:22:30.007264 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:22:42.491193 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:22:43.953571 5095 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:43.953604 5150 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:43.953626 5002 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:43.953644 4999 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:43.953716 5078 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:43.953737 5120 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:43.954290 5002 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:43.954613 5095 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:43.954626 5078 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:22:43.954894 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:22:43.955068 5089 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:43.955442 5107 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:22:43.955966 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:22:43.956037 5107 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:22:43.956542 475 server/status/runtime.go:500  [n1] runtime stats: 258 MiB RSS, 207 goroutines, 96 MiB/90 MiB/211 MiB GO alloc/idle/total, 66 MiB/79 MiB CGO alloc/total, 40.8 CGO/sec, 0.5/0.8 %(u/s)time, 0.0 %gc (1x), 906 KiB/906 KiB (r/w)net
W220119 10:22:45.882714 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:22:45.882819 134 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=1]
I220119 10:22:45.882945 5199 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:22:51.031040 127 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:22:53.175079 5263 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:53.175226 5298 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:53.175249 5294 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:53.175379 5263 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:22:53.175540 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:22:53.175567 5298 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:53.176870 5258 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
I220119 10:22:53.176901 5196 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 tripped: rpc error: code = Canceled desc = grpc: the client connection is closing
I220119 10:22:53.176907 5196 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerTripped
W220119 10:22:53.176916 5196 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23458: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:22:53.176930 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
W220119 10:22:53.178054 5300 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:22:53.178078 5333 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:22:53.178193 5300 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:22:53.182655 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 9.2s
W220119 10:22:53.182667 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:22:53.646102 146 storage/store.go:3503  [n1,s1,r91/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 9.7s [applied=0, batches=0, state_assertions=0]
W220119 10:22:54.177854 146 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 0.5s [applied=3, batches=3, state_assertions=2]
W220119 10:22:54.614622 134 storage/store.go:3503  [n1,s1,r61/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 8.7s [applied=0, batches=0, state_assertions=0]
W220119 10:22:54.614774 130 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=16, batches=8, state_assertions=4]
I220119 10:22:55.334999 5444 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerReset
I220119 10:22:55.335015 5444 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:22:55.344340 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:22:55.344959 132 storage/store.go:3503  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W220119 10:22:55.344985 129 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I220119 10:22:55.346059 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:22:57.595956 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:22:57.600088 127 storage/engine/rocksdb.go:2234  batch [763/85908/3] commit took 2.985197238s (>= warning threshold 500ms)
W220119 10:22:57.600193 127 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 3.9s [applied=3, batches=1, state_assertions=0]
I220119 10:22:57.600250 475 server/status/runtime.go:500  [n1] runtime stats: 258 MiB RSS, 219 goroutines, 113 MiB/74 MiB/211 MiB GO alloc/idle/total, 66 MiB/79 MiB CGO alloc/total, 19.9 CGO/sec, 0.2/0.1 %(u/s)time, 0.0 %gc (0x), 1.9 MiB/1.9 MiB (r/w)net
W220119 10:22:57.600430 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.4s
W220119 10:22:57.607028 146 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 3.0s [applied=1, batches=1, state_assertions=0]
W220119 10:22:57.620242 133 storage/store.go:3503  [n1,s1,r98/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W220119 10:22:57.620926 129 storage/store.go:3503  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:22:57.621021 136 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:22:57.621052 125 storage/store.go:3503  [n1,s1,r38/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:22:57.624014 140 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W220119 10:22:58.271254 129 storage/engine/rocksdb.go:2234  batch [4522/513970/0] commit took 648.308954ms (>= warning threshold 500ms)
W220119 10:22:58.271429 130 storage/store.go:3503  [n1,s1,r5/1:/{Systemtse-Table/Systemâ€¦}] handle raft ready: 2.9s [applied=2, batches=2, state_assertions=1]
W220119 10:22:58.272108 135 storage/store.go:3503  [n1,s1,r89/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=1]
W220119 10:22:58.318840 136 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W220119 10:22:58.319173 131 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 3.0s [applied=2, batches=2, state_assertions=1]
W220119 10:22:58.319329 129 storage/store.go:3503  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W220119 10:22:58.319867 144 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 3.0s [applied=2, batches=2, state_assertions=1]
W220119 10:22:58.319955 127 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=8, batches=1, state_assertions=0]
W220119 10:22:58.320862 146 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.7s [applied=12, batches=1, state_assertions=0]
W220119 10:22:58.322861 140 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=5, batches=2, state_assertions=1]
W220119 10:22:58.987737 127 storage/engine/rocksdb.go:2234  batch [762/85889/3] commit took 559.644091ms (>= warning threshold 500ms)
W220119 10:22:58.987852 127 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=3, batches=1, state_assertions=0]
I220119 10:23:01.419755 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:23:01.988050 471 gossip/gossip.go:562  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  3: ubuntu:23458 (7s: infos 12/33 sent/received, bytes 2624B/4623B sent/received)
gossip server (0/3 cur/max conns, infos 466/1189 sent/received, bytes 133137B/220993B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n3; n2 -> n3;
W220119 10:23:03.030034 145 storage/store.go:3503  [n1,s1,r41/1:/Table/5{7/1/-922â€¦-8}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W220119 10:23:03.485070 124 storage/store.go:3503  [n1,s1,r102/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W220119 10:23:03.485127 142 storage/store.go:3503  [n1,s1,r30/1:/Table/5{6-7}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W220119 10:23:08.878189 141 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 5.8s [applied=0, batches=0, state_assertions=0]
W220119 10:23:08.878379 134 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
W220119 10:23:08.878801 5364 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:08.881019 5359 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:23:08.881052 5364 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:08.883034 143 storage/store.go:3503  [n1,s1,r74/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
W220119 10:23:08.883655 127 storage/store.go:3503  [n1,s1,r44/1:/Table/58/1/-9223349785971â€¦] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
W220119 10:23:08.883722 139 storage/store.go:3503  [n1,s1,r37/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
I220119 10:23:09.281558 475 server/status/runtime.go:500  [n1] runtime stats: 254 MiB RSS, 218 goroutines, 145 MiB/44 MiB/211 MiB GO alloc/idle/total, 66 MiB/80 MiB CGO alloc/total, 60.4 CGO/sec, 1.3/0.8 %(u/s)time, 0.0 %gc (0x), 9.1 MiB/9.1 MiB (r/w)net
I220119 10:23:09.602390 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:23:09.602476 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:23:10.573890 134 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.3s [applied=3, batches=2, state_assertions=1]
W220119 10:23:10.575968 145 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:23:10.576049 135 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:23:10.854439 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 1.2s
W220119 10:23:11.144975 127 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.145309 132 storage/store.go:3503  [n1,s1,r68/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.145920 125 storage/store.go:3503  [n1,s1,r31/1:/Table/5{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.146008 139 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.146076 147 storage/store.go:3503  [n1,s1,r44/1:/Table/58/1/-9223349785971â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.146106 142 storage/store.go:3503  [n1,s1,r105/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.146129 129 storage/store.go:3503  [n1,s1,r83/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:23:11.146733 135 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.6s [applied=3, batches=1, state_assertions=0]
W220119 10:23:11.146914 145 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
W220119 10:23:11.889861 132 storage/store.go:3503  [n1,s1,r22/1:/Table/2{6-7}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W220119 10:23:15.385984 130 storage/store.go:3503  [n1,s1,r105/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 3.5s [applied=1, batches=1, state_assertions=0]
W220119 10:23:18.581262 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:23:18.581471 5677 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:23:18.585114 141 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 4.8s [applied=0, batches=0, state_assertions=0]
I220119 10:23:24.124886 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:23:24.124977 5601 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:24.125711 5576 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:23:24.127527 130 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 5.5s [applied=3, batches=3, state_assertions=1]
W220119 10:23:24.130937 5601 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:27.098558 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:23:27.100320 475 server/status/runtime.go:500  [n1] runtime stats: 242 MiB RSS, 217 goroutines, 163 MiB/27 MiB/211 MiB GO alloc/idle/total, 66 MiB/80 MiB CGO alloc/total, 23.9 CGO/sec, 0.3/0.2 %(u/s)time, 0.0 %gc (0x), 3.9 MiB/3.9 MiB (r/w)net
I220119 10:23:27.101319 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:23:28.395048 134 storage/engine/rocksdb.go:2234  batch [1509/171393/4] commit took 4.265896743s (>= warning threshold 500ms)
W220119 10:23:28.395295 134 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 9.8s [applied=4, batches=1, state_assertions=0]
W220119 10:23:30.499618 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.4s
W220119 10:23:30.499835 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:23:34.765419 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:23:34.767915 143 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 6.4s [applied=6, batches=1, state_assertions=0]
I220119 10:23:37.899396 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:23:37.900270 5809 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:23:37.900498 133 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 13.8s [applied=0, batches=0, state_assertions=0]
W220119 10:23:37.901526 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 7.4s
W220119 10:23:37.901536 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:23:38.338789 76 storage/engine/rocksdb.go:2234  batch [0/14/0] commit took 3.569827914s (>= warning threshold 500ms)
W220119 10:23:38.339766 130 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 14.2s [applied=1, batches=1, state_assertions=1]
W220119 10:23:38.339909 142 storage/store.go:3503  [n1,s1,r59/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 14.2s [applied=2, batches=1, state_assertions=0]
W220119 10:23:38.340143 139 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 14.2s [applied=3, batches=2, state_assertions=1]
W220119 10:23:38.344357 5335 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:23:38.344786 5231 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:38.345071 5436 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:23:38.345444 5396 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:38.346234 5396 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:38.346285 5231 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:38.347349 5385 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:23:38.347650 5389 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:23:38.348451 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:23:39.396377 475 server/status/runtime.go:500  [n1] runtime stats: 242 MiB RSS, 231 goroutines, 163 MiB/27 MiB/211 MiB GO alloc/idle/total, 66 MiB/78 MiB CGO alloc/total, 9.8 CGO/sec, 0.4/0.2 %(u/s)time, 0.0 %gc (0x), 610 KiB/610 KiB (r/w)net
I220119 10:23:41.170511 5537 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:23:41.172808 5389 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:41.172829 5389 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:23:41.173393 5827 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:23:41.617613 147 storage/engine/rocksdb.go:2234  batch [1510/171412/4] commit took 2.223897108s (>= warning threshold 500ms)
W220119 10:23:41.618025 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:3.623878655e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W220119 10:23:41.618463 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 11.1s [applied=4, batches=1, state_assertions=0]
W220119 10:23:42.542622 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.2s
W220119 10:23:42.542634 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:23:42.543670 128 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 3.1s [applied=4, batches=1, state_assertions=0]
W220119 10:23:42.959432 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I220119 10:23:58.227486 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:23:58.227795 128 storage/engine/rocksdb.go:2234  batch [2263/257030/5] commit took 14.823178383s (>= warning threshold 500ms)
W220119 10:23:58.227901 128 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 15.3s [applied=6, batches=1, state_assertions=0]
W220119 10:23:58.227996 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:3.623878655e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:23:58.742447 5892 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:58.742502 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:23:58.742918 5892 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:58.743150 5535 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:23:58.743170 5866 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:23:58.743428 5723 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:23:58.743537 5723 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:23:58.743991 5825 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:23:59.303856 5834 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
I220119 10:23:59.304100 475 server/status/runtime.go:500  [n1] runtime stats: 246 MiB RSS, 229 goroutines, 125 MiB/62 MiB/212 MiB GO alloc/idle/total, 66 MiB/79 MiB CGO alloc/total, 15.1 CGO/sec, 0.3/0.2 %(u/s)time, 10.6 %gc (1x), 972 KiB/972 KiB (r/w)net
W220119 10:24:04.901123 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.2s
W220119 10:24:04.901133 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:24:05.724618 5900 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:05.724807 5838 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:05.725650 146 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 7.0s [applied=0, batches=0, state_assertions=0]
I220119 10:24:05.725750 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (2/3 cur/max conns)
  0: ubuntu:23458 (7s: infos 0/0 sent/received, bytes 0B/0B sent/received)
  0: ubuntu:23457 (0s: infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip server (0/3 cur/max conns, infos 516/1340 sent/received, bytes 181628B/239951B sent/received)
gossip connectivity
W220119 10:24:05.726111 5838 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:24:05.767384 142 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 21.8s [applied=0, batches=0, state_assertions=0]
W220119 10:24:05.767952 5900 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:24:05.769563 127 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 7.0s [applied=0, batches=0, state_assertions=0]
W220119 10:24:05.769694 124 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 21.8s [applied=6, batches=6, state_assertions=3]
W220119 10:24:05.769893 153 storage/store.go:1580  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] could not gossip first range descriptor: [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown
I220119 10:24:05.771227 6061 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:24:05.771591 5917 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:24:07.033207 147 storage/engine/rocksdb.go:2234  batch [3016/342636/5] commit took 757.473137ms (>= warning threshold 500ms)
W220119 10:24:07.033337 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=7, batches=1, state_assertions=0]
W220119 10:24:07.033978 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:2.281701375e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:24:07.039546 139 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W220119 10:24:07.039808 130 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I220119 10:24:07.684891 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:24:07.686063 124 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.4s [applied=3, batches=1, state_assertions=0]
W220119 10:24:07.689642 5931 storage/node_liveness.go:523  [n1,s1,r7/1:/Table/1{1-2}] slow heartbeat took 8.4s
W220119 10:24:07.689872 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.8s
W220119 10:24:07.690243 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=2, batches=1, state_assertions=0]
I220119 10:24:08.261109 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:24:13.044291 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:24:13.044305 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.8s
W220119 10:24:13.044313 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:24:13.045016 141 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
W220119 10:24:13.047017 143 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 4.8s [applied=0, batches=0, state_assertions=0]
W220119 10:24:13.049658 131 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 5.4s [applied=4, batches=2, state_assertions=1]
W220119 10:24:13.049807 124 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 5.4s [applied=2, batches=1, state_assertions=0]
W220119 10:24:14.419453 134 storage/store.go:3503  [n1,s1,r74/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W220119 10:24:14.419621 146 storage/store.go:3503  [n1,s1,r5/1:/{Systemtse-Table/Systemâ€¦}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W220119 10:24:14.419684 142 storage/store.go:3503  [n1,s1,r89/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W220119 10:24:15.658494 145 storage/store.go:3503  [n1,s1,r107/1:/Table/58/1/-92233497859701â€¦] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W220119 10:24:15.658599 132 storage/store.go:3503  [n1,s1,r44/1:/Table/58/1/-9223349785971â€¦] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W220119 10:24:15.658630 129 storage/store.go:3503  [n1,s1,r97/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W220119 10:24:15.658651 126 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W220119 10:24:15.660626 147 storage/engine/rocksdb.go:2234  batch [2260/256961/4] commit took 2.609631942s (>= warning threshold 500ms)
W220119 10:24:15.660701 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 8.0s [applied=4, batches=1, state_assertions=0]
W220119 10:24:15.661805 135 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 2.6s [applied=2, batches=2, state_assertions=1]
I220119 10:24:15.661889 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 225 goroutines, 148 MiB/42 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 32.2 CGO/sec, 0.4/0.3 %(u/s)time, 0.0 %gc (0x), 1.0 MiB/1.0 MiB (r/w)net
W220119 10:24:15.661988 131 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.6s [applied=3, batches=1, state_assertions=0]
W220119 10:24:24.212353 6058 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:24:24.212505 6152 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:24:24.213003 6084 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:24.213057 128 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 11.2s [applied=0, batches=0, state_assertions=0]
W220119 10:24:24.213634 6084 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:24:24.213686 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 11.2s
I220119 10:24:24.213696 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
I220119 10:24:32.129680 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:24:32.130528 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:24:32.132484 6033 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I220119 10:24:32.132534 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:24:32.132561 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 7.9s
W220119 10:24:32.132580 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:24:32.132686 131 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 16.5s [applied=3, batches=2, state_assertions=1]
W220119 10:24:32.132756 6104 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:24:32.132811 130 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 16.5s [applied=0, batches=0, state_assertions=0]
W220119 10:24:32.133007 6057 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:24:32.133122 6110 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:32.133229 6234 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:24:32.133362 6233 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:24:32.133414 6110 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:24:32.133675 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:24:32.134089 6063 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:37.593460 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.5s
W220119 10:24:37.593470 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:24:37.593681 6099 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:37.593788 6252 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:24:37.593941 6248 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:24:37.594745 6063 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I220119 10:24:37.594902 5908 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
I220119 10:24:37.594911 5908 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:24:37.594921 5908 rpc/nodedialer/nodedialer.go:149  [n1,intExec=read-setting,txn=de6c78a3] unable to connect to n3: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
W220119 10:24:37.595391 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
W220119 10:24:43.760275 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:24:43.760411 6228 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:24:43.760423 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:24:43.760907 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 213 goroutines, 156 MiB/35 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 1.4 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (0x), 1.9 MiB/1.9 MiB (r/w)net
W220119 10:24:43.761325 6099 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:24:43.761888 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.2s
W220119 10:24:43.761901 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:24:43.762185 124 storage/store.go:3503  [n1,s1,r87/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 6.2s [applied=0, batches=0, state_assertions=0]
I220119 10:24:43.762859 6158 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:24:43.762873 6158 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:24:43.762887 6158 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:24:43.762980 6251 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:24:43.763206 130 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 11.6s [applied=0, batches=0, state_assertions=0]
I220119 10:24:43.763373 6379 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 tripped: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:24:43.763376 6379 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerTripped
W220119 10:24:43.763380 125 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 11.6s [applied=0, batches=0, state_assertions=0]
W220119 10:24:43.763387 6379 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:24:43.763443 137 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 6.2s [applied=0, batches=0, state_assertions=0]
W220119 10:24:43.763553 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1} {StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:2.684354559e+09}]}
I220119 10:24:43.764232 6070 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:24:43.764243 6070 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:24:43.764253 6070 rpc/nodedialer/nodedialer.go:149  [n1,intExec=find-scheduled-jobs,txn=8fd303d9] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:24:48.136160 128 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 23.9s [applied=1, batches=1, state_assertions=0]
W220119 10:24:48.145057 121 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 4.4s [applied=0, batches=0, state_assertions=0]
W220119 10:24:48.145266 142 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 23.9s [applied=1, batches=1, state_assertions=0]
I220119 10:24:48.145741 6389 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:24:48.146601 6420 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:24:48.149803 116 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 4.4s [applied=0, batches=0, state_assertions=0]
I220119 10:24:48.150716 6321 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:24:48.151013 6336 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:24:48.151274 153 storage/store.go:1580  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] could not gossip first range descriptor: [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown
W220119 10:24:52.219215 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 8.5s
W220119 10:24:52.219241 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
I220119 10:24:57.279843 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:24:57.280256 6505 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:24:57.280332 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:24:57.280673 6420 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:24:57.280721 6336 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I220119 10:24:57.286174 6502 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:24:57.286529 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:24:57.286539 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.1s
W220119 10:24:57.286550 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:24:57.287529 6345 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:57.287586 6345 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:24:57.287744 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 219 goroutines, 168 MiB/23 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 12.8 CGO/sec, 0.3/0.1 %(u/s)time, 0.0 %gc (0x), 688 KiB/687 KiB (r/w)net
W220119 10:24:57.287867 6381 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:24:57.287894 6421 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:24:57.287913 6505 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I220119 10:24:57.288700 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:24:57.291447 128 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 9.1s [applied=34, batches=13, state_assertions=6]
W220119 10:24:57.291710 129 storage/store.go:3503  [n1,s1,r88/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 9.1s [applied=0, batches=0, state_assertions=0]
W220119 10:24:57.291764 147 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 9.1s [applied=0, batches=0, state_assertions=0]
W220119 10:25:14.173569 6480 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:25:14.174722 6557 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:25:14.174747 6558 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:25:14.175858 6330 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:14.175955 6555 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:25:14.176110 6425 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:14.176138 6425 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:25:14.176347 6381 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:25:14.176916 5506 storage/replica_range_lease.go:986  [n1,s1,r7/1:/Table/1{1-2}] have been waiting 1m0s attempting to acquire lease
I220119 10:25:14.177089 6523 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:25:14.177167 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 16.9s
W220119 10:25:14.177172 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:25:14.187379 6162 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:25:15.644895 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  0: ubuntu:23458 (1s: infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip server (0/3 cur/max conns, infos 582/1517 sent/received, bytes 190439B/262156B sent/received)
W220119 10:25:15.645320 6028 storage/replica_range_lease.go:986  [n1,s1,r7/1:/Table/1{1-2}] have been waiting 1m0s attempting to acquire lease
I220119 10:25:15.646557 475 server/status/runtime.go:500  [n1] runtime stats: 249 MiB RSS, 202 goroutines, 176 MiB/16 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 19.1 CGO/sec, 0.1/0.1 %(u/s)time, 0.0 %gc (0x), 443 KiB/443 KiB (r/w)net
I220119 10:25:15.646581 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:25:15.647970 6330 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:25:15.650571 6630 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:25:15.650711 5931 storage/replica_write.go:191  [n1,s1,r7/1:/Table/1{1-2}] have been waiting 66.50s for proposing command RequestLease [/Table/11,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/7

and the following Raft status: {"id":"1","term":33,"vote":"0","commit":500,"lead":"2","raftState":"StateFollower","applied":500,"progress":{},"leadtransferee":"0"}
W220119 10:25:15.651676 6660 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:25:15.651700 6162 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:25:15.652550 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:4.563402751e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:6}]}
W220119 10:25:53.137957 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:25:53.138228 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 37.5s
W220119 10:25:53.138236 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:25:53.138444 146 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 37.5s [applied=2, batches=2, state_assertions=1]
I220119 10:25:53.139474 5931 storage/replica_write.go:208  [n1,s1,r7/1:/Table/1{1-2}] slow command RequestLease [/Table/11,/Min) finished after 105.45s with error <nil>
I220119 10:25:53.139808 6028 storage/replica_range_lease.go:991  [n1,s1,r7/1:/Table/1{1-2}] slow lease acquisition finished after 1m47.414020272s with error <nil> after 1 attempts
I220119 10:25:53.141280 5506 storage/replica_range_lease.go:991  [n1,s1,r7/1:/Table/1{1-2}] slow lease acquisition finished after 1m53.836469495s with error <nil> after 1 attempts
W220119 10:25:53.141299 6485 storage/replica_write.go:191  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 60.92s for proposing command RequestLease [/Min,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/1

and the following Raft status: {"id":"1","term":13,"vote":"0","commit":3118,"lead":"2","raftState":"StateFollower","applied":3118,"progress":{},"leadtransferee":"0"}
I220119 10:25:53.142431 6633 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:25:53.142483 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:25:53.142486 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:25:53.142523 153 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:25:53.142571 6636 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:53.169525 6636 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:25:53.172190 6662 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = Unavailable desc = transport is closing
I220119 10:25:53.172206 6662 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:25:53.172216 6662 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:25:53.172298 6672 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:53.172349 6661 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:25:53.172428 6668 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:53.172520 6643 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:25:53.172540 6623 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:25:53.172972 155 storage/store.go:1580  [n1,s1,r2/1:/System/NodeLiveness{-Max}] could not gossip node liveness: [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown
I220119 10:25:53.173766 475 server/status/runtime.go:500  [n1] runtime stats: 247 MiB RSS, 225 goroutines, 178 MiB/14 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 1.2 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (0x), 760 KiB/759 KiB (r/w)net
W220119 10:26:03.913000 6672 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:26:03.913026 6668 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:26:03.913035 6643 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:26:03.913652 6711 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:26:03.914471 6689 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:26:03.914535 6416 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:26:03.914665 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  0: ubuntu:23457 (11s: infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip server (0/3 cur/max conns, infos 588/1563 sent/received, bytes 191447B/267763B sent/received)
W220119 10:26:03.915507 6711 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:26:03.915984 6694 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:26:03.915993 6694 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:26:03.916012 6694 rpc/nodedialer/nodedialer.go:149  [n1,s1,r7/1:/Table/1{1-2},txn=53ec6c93] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:26:03.916175 6738 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 tripped: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:26:03.916179 6738 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerTripped
W220119 10:26:03.917212 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 10.8s
W220119 10:26:03.917232 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:26:04.443025 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:26:04.444015 475 server/status/runtime.go:500  [n1] runtime stats: 248 MiB RSS, 178 goroutines, 178 MiB/14 MiB/212 MiB GO alloc/idle/total, 74 MiB/87 MiB CGO alloc/total, 13.0 CGO/sec, 0.2/0.0 %(u/s)time, 0.0 %gc (0x), 370 KiB/369 KiB (r/w)net
I220119 10:26:04.465320 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: show-version: operation "show cluster setting version" timed out after 2m0s
I220119 10:26:05.666303 6884 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:26:12.405885 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 8.5s
W220119 10:26:12.405903 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:26:12.409921 141 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 7.4s [applied=0, batches=0, state_assertions=0]
W220119 10:26:12.409992 6473 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:26:12.410014 6476 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:26:12.410241 6747 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:26:12.411903 129 storage/store.go:3503  [n1,s1,r96/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 6.4s [applied=1, batches=1, state_assertions=0]
I220119 10:26:12.493773 6694 storage/node_liveness.go:775  [n1,s1,r7/1:/Table/1{1-2}] retrying liveness update after storage.errRetryLiveness: result is ambiguous (error=failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded [exhausted])
W220119 10:26:12.496860 6694 storage/node_liveness.go:523  [n1,s1,r7/1:/Table/1{1-2}] slow heartbeat took 19.4s
I220119 10:26:12.497132 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
I220119 10:26:14.443938 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:26:14.446253 475 server/status/runtime.go:500  [n1] runtime stats: 251 MiB RSS, 232 goroutines, 158 MiB/37 MiB/215 MiB GO alloc/idle/total, 73 MiB/88 MiB CGO alloc/total, 87.6 CGO/sec, 0.3/1.4 %(u/s)time, 0.3 %gc (1x), 974 KiB/974 KiB (r/w)net
I220119 10:26:14.708052 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:26:16.478389 7095 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
I220119 10:26:18.579388 6485 storage/replica_write.go:208  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow command RequestLease [/Min,/Min) finished after 86.36s with error cannot replace lease repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587986.807124243,0 pro=1642587977.807144141,0 with repl=(n1,s1):1 seq=13 start=1642587860.807710223,1 exp=1642587901.218658002,0 pro=1642587892.218666528,0: proposed under invalid lease
I220119 10:26:18.579522 153 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m26.360830914s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587986.807124243,0 pro=1642587977.807144141,0 after 1 attempts
I220119 10:26:18.579888 6476 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m21.292586678s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587986.807124243,0 pro=1642587977.807144141,0 after 1 attempts
I220119 10:26:18.580019 6473 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m21.292806354s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587986.807124243,0 pro=1642587977.807144141,0 after 1 attempts
I220119 10:26:18.580197 6416 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m21.292292004s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642587986.807124243,0 pro=1642587977.807144141,0 after 1 attempts
W220119 10:26:18.597208 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:3}]}
I220119 10:26:24.444805 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:26:24.448697 475 server/status/runtime.go:500  [n1] runtime stats: 275 MiB RSS, 213 goroutines, 148 MiB/52 MiB/221 MiB GO alloc/idle/total, 19 MiB/30 MiB CGO alloc/total, 145.3 CGO/sec, 4.0/4.0 %(u/s)time, 0.0 %gc (0x), 927 KiB/927 KiB (r/w)net
I220119 10:26:34.724203 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:26:34.726056 475 server/status/runtime.go:500  [n1] runtime stats: 263 MiB RSS, 214 goroutines, 164 MiB/37 MiB/221 MiB GO alloc/idle/total, 20 MiB/30 MiB CGO alloc/total, 30.2 CGO/sec, 0.6/1.1 %(u/s)time, 0.0 %gc (0x), 566 KiB/566 KiB (r/w)net
W220119 10:26:57.451126 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:26:57.451783 7381 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerReset
I220119 10:26:57.451794 7381 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:26:57.452472 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:26:57.452484 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 18.3s
W220119 10:26:57.452493 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:26:57.453471 130 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 18.3s [applied=4, batches=1, state_assertions=0]
W220119 10:26:57.453516 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:26:57.453795 141 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 18.3s [applied=3, batches=2, state_assertions=1]
I220119 10:26:57.454599 475 server/status/runtime.go:500  [n1] runtime stats: 217 MiB RSS, 216 goroutines, 164 MiB/37 MiB/221 MiB GO alloc/idle/total, 20 MiB/31 MiB CGO alloc/total, 5.2 CGO/sec, 0.0/0.2 %(u/s)time, 0.0 %gc (0x), 1.1 MiB/1.1 MiB (r/w)net
W220119 10:26:57.455617 6803 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:26:57.455714 6885 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:26:57.455829 6945 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:26:57.455849 6892 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:26:57.455854 6884 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:26:57.455882 6892 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:26:57.456080 6964 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:26:57.456123 7095 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:26:57.456554 6807 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:26:57.456601 6807 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:26:57.457538 6964 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:26:57.457835 6945 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:26:57.460080 128 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 18.3s [applied=3, batches=1, state_assertions=0]
I220119 10:26:57.469240 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:26:57.534239 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:26:57.610248 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 2 not running (UNAVAILABLE), cannot determine version
W220119 10:26:57.932214 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:26:58.451696 7525 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:26:59.186595 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:27:00.453490 7393 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:27:00.783813 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (error=rpc error: code = Unavailable desc = transport is closing [propagate])
W220119 10:27:00.783827 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 3.3s
I220119 10:27:00.783832 482 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
W220119 10:27:01.263158 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:27:01.983489 471 gossip/gossip.go:562  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  3: ubuntu:23458 (4s: infos 7/27 sent/received, bytes 982B/3266B sent/received)
gossip server (0/3 cur/max conns, infos 629/1704 sent/received, bytes 198856B/286864B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n3; n2 -> n3;
W220119 10:27:23.695903 7486 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:23.695954 7482 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:23.695980 7486 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:27:23.696022 7498 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:23.696124 7424 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:23.696181 7466 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:23.696197 7461 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:23.696207 7424 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:27:23.696224 7466 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:27:23.698249 7453 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:23.698480 7457 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:24.991861 7457 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:24.992812 136 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:27:24.992885 124 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:27:24.992929 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:27:24.993589 482 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
I220119 10:27:24.993598 482 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:27:24.993606 482 rpc/nodedialer/nodedialer.go:149  [n1,hb,txn=48046ec2] unable to connect to n3: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
W220119 10:27:26.080498 7457 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:27:26.081872 475 server/status/runtime.go:500  [n1] runtime stats: 210 MiB RSS, 181 goroutines, 180 MiB/21 MiB/221 MiB GO alloc/idle/total, 20 MiB/33 MiB CGO alloc/total, 19.1 CGO/sec, 0.4/0.5 %(u/s)time, 0.1 %gc (1x), 1.4 MiB/1.4 MiB (r/w)net
I220119 10:27:29.182047 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:27:30.350167 7630 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:27:30.350245 7613 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:27:30.350252 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:27:30.350375 7764 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:27:30.351675 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:27:30.351689 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.4s
W220119 10:27:30.351698 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:27:32.070792 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:27:39.535565 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:27:39.537750 126 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 7.5s [applied=3, batches=3, state_assertions=1]
I220119 10:27:39.537816 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:27:39.538001 7707 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:39.538081 129 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 8.2s [applied=1, batches=1, state_assertions=0]
I220119 10:27:39.538406 7757 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:27:39.538560 7718 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:39.538706 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 9.2s
W220119 10:27:39.538711 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:27:39.539713 7718 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:27:39.539912 475 server/status/runtime.go:500  [n1] runtime stats: 209 MiB RSS, 230 goroutines, 113 MiB/84 MiB/221 MiB GO alloc/idle/total, 20 MiB/33 MiB CGO alloc/total, 24.2 CGO/sec, 0.1/0.2 %(u/s)time, 0.0 %gc (0x), 1.1 MiB/1.1 MiB (r/w)net
I220119 10:27:39.542116 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:27:39.543030 7613 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:39.543922 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:5.368709119e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:27:39.544153 7703 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:39.544183 7626 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:27:39.544257 7703 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:27:39.544702 7615 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:27:39.544724 7615 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:27:39.546163 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
W220119 10:27:39.589565 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:5.368709119e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I220119 10:27:39.694351 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:27:40.537207 7949 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:27:41.909556 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:27:45.044871 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:5.368709119e+09}]}
I220119 10:27:49.538006 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:27:49.542029 475 server/status/runtime.go:500  [n1] runtime stats: 253 MiB RSS, 213 goroutines, 134 MiB/67 MiB/226 MiB GO alloc/idle/total, 52 MiB/73 MiB CGO alloc/total, 362.4 CGO/sec, 15.5/8.2 %(u/s)time, 0.0 %gc (2x), 4.4 MiB/4.4 MiB (r/w)net
W220119 10:27:59.176209 139 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.6s [applied=3, batches=2, state_assertions=1]
W220119 10:27:59.179958 142 storage/store.go:3503  [n1,s1,r33/1:/Table/58{-/1/-9223â€¦}] handle raft ready: 4.6s [applied=1, batches=1, state_assertions=1]
I220119 10:28:01.855797 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:28:01.856920 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.7s
I220119 10:28:01.857000 475 server/status/runtime.go:500  [n1] runtime stats: 254 MiB RSS, 216 goroutines, 134 MiB/67 MiB/226 MiB GO alloc/idle/total, 52 MiB/73 MiB CGO alloc/total, 26.4 CGO/sec, 0.1/0.6 %(u/s)time, 0.0 %gc (0x), 910 KiB/910 KiB (r/w)net
I220119 10:28:03.397545 471 gossip/gossip.go:562  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  2: ubuntu:23457 (23s: infos 72/138 sent/received, bytes 21306B/26029B sent/received)
gossip server (0/3 cur/max conns, infos 731/1943 sent/received, bytes 224077B/325040B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n2; n2 -> n3;
W220119 10:28:03.400579 141 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 4.2s [applied=4, batches=1, state_assertions=0]
W220119 10:28:03.407598 142 storage/store.go:3503  [n1,s1,r33/1:/Table/58{-/1/-9223â€¦}] handle raft ready: 4.2s [applied=1, batches=1, state_assertions=0]
W220119 10:28:03.408434 145 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.2s [applied=0, batches=0, state_assertions=0]
W220119 10:28:04.000917 140 storage/store.go:3503  [n1,s1,r71/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=1]
W220119 10:28:04.001000 145 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=2, batches=1, state_assertions=0]
I220119 10:28:07.030523 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
W220119 10:28:10.190582 126 storage/store.go:3503  [n1,s1,r53/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W220119 10:28:10.194083 146 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W220119 10:28:11.804619 131 storage/store.go:3503  [n1,s1,r82/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
I220119 10:28:13.785232 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:28:13.786782 475 server/status/runtime.go:500  [n1] runtime stats: 255 MiB RSS, 215 goroutines, 143 MiB/60 MiB/226 MiB GO alloc/idle/total, 52 MiB/73 MiB CGO alloc/total, 40.5 CGO/sec, 0.8/0.5 %(u/s)time, 0.0 %gc (0x), 9.6 MiB/9.6 MiB (r/w)net
W220119 10:28:15.845529 138 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=2, batches=1, state_assertions=0]
W220119 10:28:16.549759 142 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W220119 10:28:16.569057 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W220119 10:28:17.327751 147 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.8s [applied=3, batches=1, state_assertions=0]
W220119 10:28:20.003403 124 storage/store.go:3503  [n1,s1,r100/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:28:21.552306 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 1.5s
W220119 10:28:26.813440 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:28:26.827534 8549 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:28:34.768095 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:28:34.768122 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:28:34.768384 7627 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:28:34.768677 7840 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:28:34.768737 7926 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:28:34.768767 7687 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:34.768896 7687 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:28:34.769210 7899 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:34.769437 7843 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:34.769780 7899 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:28:34.770410 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:28:34.770816 7843 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:28:34.772050 7887 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
I220119 10:28:51.628488 8553 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:28:51.628500 8553 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:28:51.628510 8553 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:28:51.628615 79 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
I220119 10:28:51.629455 482 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:28:51.629472 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 24.8s
W220119 10:28:51.629482 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:28:51.629513 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:28:51.629591 8538 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:28:51.629597 8538 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:28:51.629607 8538 rpc/nodedialer/nodedialer.go:149  [n1,intExec=find-scheduled-jobs,txn=b0917608] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:28:51.629813 7891 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:51.630189 7891 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:28:51.630870 8601 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:51.636485 8601 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:28:51.631373 8585 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:51.636504 8585 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
W220119 10:28:51.631594 8590 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:28:51.636519 8590 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I220119 10:28:51.634946 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:28:51.636441 124 storage/engine/rocksdb.go:2234  batch [2/105/0] commit took 1.496330357s (>= warning threshold 500ms)
W220119 10:28:51.636978 8598 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
I220119 10:28:51.637803 475 server/status/runtime.go:500  [n1] runtime stats: 254 MiB RSS, 191 goroutines, 192 MiB/13 MiB/226 MiB GO alloc/idle/total, 60 MiB/81 MiB CGO alloc/total, 8.3 CGO/sec, 0.2/0.1 %(u/s)time, 0.0 %gc (0x), 3.9 MiB/3.9 MiB (r/w)net
W220119 10:28:51.638042 147 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 31.6s [applied=2, batches=1, state_assertions=0]
W220119 10:28:51.638377 124 storage/store.go:3503  [n1,s1,r100/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 31.6s [applied=1, batches=1, state_assertions=1]
W220119 10:28:51.707208 132 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 16.9s [applied=0, batches=0, state_assertions=0]
I220119 10:28:51.708438 8632 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:28:56.537909 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:28:56.539515 135 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.7s [applied=11, batches=1, state_assertions=0]
W220119 10:28:56.539541 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 4.9s
W220119 10:28:56.539548 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
I220119 10:28:56.539762 8571 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:29:00.109238 470 storage/store.go:4034  [n1,s1] sstables (read amplification = 1):
6 [ 20M 3 ]: 15M 3M 2M
I220119 10:29:00.109977 470 storage/store.go:4035  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0     13.3      0.34              0.23         2    0.170       0      0
  L6      3/0   19.86 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.1     84.0     49.6      0.10              0.10         2    0.052     78K    23K
 Sum      3/0   19.86 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   2.1     19.7     21.8      0.45              0.33         4    0.111     78K    23K
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   2.1     16.3     18.8      0.30              0.29         2    0.150     43K    15K

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Low      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0     84.0     49.6      0.10              0.10         2    0.052     78K    23K
High      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0     11.0      0.24              0.23         1    0.244       0      0
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0     19.1      0.10              0.00         1    0.096       0      0
Uptime(secs): 958.7 total, 918.1 interval
Flush(GB): cumulative 0.004, interval 0.003
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.01 GB write, 0.01 MB/s write, 0.01 GB read, 0.01 MB/s read, 0.4 seconds
Interval compaction: 0.01 GB write, 0.01 MB/s write, 0.00 GB read, 0.01 MB/s read, 0.3 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
W220119 10:29:00.110300 133 storage/engine/rocksdb.go:2234  batch [1/49/0] commit took 3.569913761s (>= warning threshold 500ms)
W220119 10:29:00.110357 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:29:00.110414 144 storage/store.go:3503  [n1,s1,r24/1:/Table/2{8-9}] handle raft ready: 3.6s [applied=0, batches=0, state_assertions=0]
W220119 10:29:00.111905 133 storage/store.go:3503  [n1,s1,r27/1:/Table/{31-51}] handle raft ready: 3.6s [applied=0, batches=0, state_assertions=0]
I220119 10:29:00.112255 8798 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
I220119 10:29:06.769123 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:29:06.769327 8725 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:29:06.769411 8748 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:06.769519 8642 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:06.769566 8748 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:29:06.769625 8795 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 tripped: rpc error: code = Canceled desc = grpc: the client connection is closing
I220119 10:29:06.769630 8795 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerTripped
W220119 10:29:06.769641 8795 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23458: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:29:06.769655 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:29:06.769721 8755 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:29:06.769733 8642 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:29:06.769968 8765 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = Unavailable desc = transport is closing
I220119 10:29:06.769972 8765 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
W220119 10:29:06.770001 8798 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:29:06.770020 8782 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:06.770035 8784 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:06.770068 8782 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:29:06.770080 8784 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:29:06.771018 8711 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:29:06.771053 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 10.2s
W220119 10:29:06.771068 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:29:06.771218 8639 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:06.771266 135 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 10.2s [applied=2, batches=1, state_assertions=0]
I220119 10:29:06.775034 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 801/2109 sent/received, bytes 316376B/347269B sent/received)
gossip connectivity
W220119 10:29:06.777745 8639 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:29:06.778320 475 server/status/runtime.go:500  [n1] runtime stats: 254 MiB RSS, 190 goroutines, 192 MiB/13 MiB/226 MiB GO alloc/idle/total, 60 MiB/81 MiB CGO alloc/total, 12.0 CGO/sec, 0.1/0.2 %(u/s)time, 0.0 %gc (0x), 665 KiB/664 KiB (r/w)net
I220119 10:29:13.340702 8717 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:13.340718 8717 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:29:13.340794 477 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:13.340801 477 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:29:13.340843 477 rpc/nodedialer/nodedialer.go:149  [n1,summaries] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:29:13.347932 135 storage/engine/rocksdb.go:2234  batch [14/29050/3] commit took 1.37861323s (>= warning threshold 500ms)
W220119 10:29:13.348828 135 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 6.6s [applied=2, batches=1, state_assertions=0]
W220119 10:29:17.527609 135 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 4.2s [applied=0, batches=0, state_assertions=0]
I220119 10:29:20.104419 8903 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 tripped: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:20.104429 8903 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerTripped
W220119 10:29:20.104447 8903 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:24.931656 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:29:24.932737 475 server/status/runtime.go:500  [n1] runtime stats: 255 MiB RSS, 198 goroutines, 202 MiB/3.3 MiB/226 MiB GO alloc/idle/total, 60 MiB/81 MiB CGO alloc/total, 2.0 CGO/sec, 0.1/0.1 %(u/s)time, 0.0 %gc (0x), 607 KiB/607 KiB (r/w)net
W220119 10:29:24.934247 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:29:27.314802 8983 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:27.314814 8983 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:29:27.314823 8983 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:27.316585 8982 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:27.316596 8982 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:29:27.316620 9038 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:27.316623 9038 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:29:27.317849 8721 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 tripped: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:27.317866 8721 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerTripped
I220119 10:29:44.836267 9059 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:29:44.836953 153 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:29:44.837066 9062 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:44.837072 9062 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
W220119 10:29:44.837495 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 19.9s
W220119 10:29:44.837506 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:29:44.837522 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:29:44.837571 9042 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:44.837575 9042 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:29:44.837644 9065 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 tripped: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:29:44.837648 9065 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerTripped
W220119 10:29:44.837687 9059 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:29:44.837720 8891 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:44.838376 8916 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:44.838412 8891 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:29:44.838443 8916 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:29:44.838871 475 server/status/runtime.go:500  [n1] runtime stats: 256 MiB RSS, 217 goroutines, 145 MiB/61 MiB/226 MiB GO alloc/idle/total, 60 MiB/81 MiB CGO alloc/total, 3.3 CGO/sec, 0.1/0.1 %(u/s)time, 12.9 %gc (1x), 494 KiB/494 KiB (r/w)net
W220119 10:29:50.268416 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.4s
W220119 10:29:50.268436 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:29:50.268608 8863 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:29:50.268792 8863 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:29:50.268826 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:29:50.268868 8863 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:30:06.376309 8727 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
I220119 10:30:06.376338 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (0/3 cur/max conns, infos 801/2109 sent/received, bytes 316376B/347269B sent/received)
W220119 10:30:06.377113 8909 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:30:06.377336 9150 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:30:06.377452 8726 storage/replica_range_lease.go:986  [n1,replicate,s1,r9/1:/Table/1{3-4}] have been waiting 1m0s attempting to acquire lease
I220119 10:30:06.377463 9150 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:30:06.377473 9150 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:30:06.377347 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:30:06.377934 8726 storage/replica_range_lease.go:991  [n1,replicate,s1,r9/1:/Table/1{3-4}] slow lease acquisition finished after 1m14.671523473s with error [NotLeaseHolderError] r9: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:30:06.377358 8896 vendor/google.golang.org/grpc/clientconn.go:1411  grpc: addrConn.transportMonitor didn't get server preface after waiting. Closing the new transport now.
W220119 10:30:06.378155 8896 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:30:06.378170 8727 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m9.838444053s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:30:06.378235 8727 storage/node_liveness.go:523  [n1,s1,r9/1:/Table/1{3-4}] slow heartbeat took 74.7s
E220119 10:30:06.378240 8727 storage/replica_range_lease.go:292  [n1,s1,r9/1:/Table/1{3-4}] aborted during DistSender.Send: context canceled
W220119 10:30:06.378257 8742 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:06.378275 8635 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:30:06.378285 8635 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m14.671814815s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:30:06.378876 8482 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:06.379087 8411 storage/replica_write.go:191  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 70.07s for proposing command RequestLease [/Min,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/1

and the following Raft status: {"id":"1","term":13,"vote":"0","commit":3190,"lead":"2","raftState":"StateFollower","applied":3190,"progress":{},"leadtransferee":"0"}
W220119 10:30:06.379239 8572 storage/replica_write.go:191  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 74.75s for proposing command RequestLease [/System/NodeLiveness,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/2

and the following Raft status: {"id":"1","term":17,"vote":"0","commit":10987,"lead":"3","raftState":"StateFollower","applied":10987,"progress":{},"leadtransferee":"0"}
E220119 10:30:06.379388 8635 storage/queue.go:977  [n1,replicaGC,s1,r74/1:/Table/58/1/-92233497859706â€¦] aborted during DistSender.Send: context deadline exceeded
W220119 10:30:06.379697 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 16.1s
W220119 10:30:06.379703 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
I220119 10:30:09.675874 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:30:09.675967 9135 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:30:09.676013 120 storage/store.go:3503  [n1,s1,r23/1:/Table/2{7-8}] handle raft ready: 3.3s [applied=0, batches=0, state_assertions=0]
W220119 10:30:09.676880 8909 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:30:09.676918 8909 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:30:17.653145 8969 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:30:17.653158 8969 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:30:17.653168 8969 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n3: failed to connect to n3 at ubuntu:23458: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:30:17.654963 9119 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerReset
I220119 10:30:17.654982 9119 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:30:17.655922 475 server/status/runtime.go:500  [n1] runtime stats: 252 MiB RSS, 209 goroutines, 139 MiB/67 MiB/226 MiB GO alloc/idle/total, 60 MiB/81 MiB CGO alloc/total, 1.4 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (0x), 760 KiB/760 KiB (r/w)net
W220119 10:30:17.657058 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 11.3s
W220119 10:30:17.657075 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:30:17.657154 9151 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:30:17.657161 9151 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:30:17.657170 9151 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:30:17.659930 8856 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:30:17.660063 9217 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:30:17.660178 8764 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:17.660304 8896 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:30:17.662045 9260 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerReset
I220119 10:30:17.662164 9260 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:30:22.731366 137 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 5.1s [applied=0, batches=0, state_assertions=0]
W220119 10:30:22.732127 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.1s
W220119 10:30:22.732142 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:30:22.732178 134 storage/store.go:3503  [n1,s1,r37/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 5.1s [applied=0, batches=0, state_assertions=0]
I220119 10:30:22.732388 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:30:22.733184 9203 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:30:24.649861 132 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.651838 133 storage/store.go:3503  [n1,s1,r79/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
I220119 10:30:24.651961 9384 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:30:24.652718 136 storage/store.go:3503  [n1,s1,r61/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.652861 145 storage/store.go:3503  [n1,s1,r90/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.652900 131 storage/store.go:3503  [n1,s1,r42/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.652924 128 storage/store.go:3503  [n1,s1,r49/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.652969 134 storage/store.go:3503  [n1,s1,r54/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.652979 147 storage/store.go:3503  [n1,s1,r65/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653018 141 storage/store.go:3503  [n1,s1,r78/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653180 124 storage/store.go:3503  [n1,s1,r95/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653260 146 storage/store.go:3503  [n1,s1,r63/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653306 144 storage/store.go:3503  [n1,s1,r92/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653343 135 storage/store.go:3503  [n1,s1,r99/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653375 138 storage/store.go:3503  [n1,s1,r75/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653855 126 storage/store.go:3503  [n1,s1,r58/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.653901 137 storage/store.go:3503  [n1,s1,r70/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:24.659533 140 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=112, batches=44, state_assertions=22]
I220119 10:30:24.659688 9388 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
I220119 10:30:26.587923 79 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:30:26.588689 155 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:26.590076 140 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=1, batches=1, state_assertions=0]
W220119 10:30:26.592479 137 storage/store.go:3503  [n1,s1,r59/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:28.782105 130 storage/engine/rocksdb.go:2234  batch [23/317463/0] commit took 2.189199629s (>= warning threshold 500ms)
W220119 10:30:28.782186 8955 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:28.782279 146 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.2s [applied=1, batches=1, state_assertions=0]
W220119 10:30:28.784375 136 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 4.1s [applied=40, batches=40, state_assertions=21]
W220119 10:30:28.785568 144 storage/store.go:3503  [n1,s1,r52/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W220119 10:30:28.785568 147 storage/store.go:3503  [n1,s1,r59/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W220119 10:30:28.786642 130 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 2.2s [applied=20, batches=1, state_assertions=0]
W220119 10:30:28.788057 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.1s
W220119 10:30:28.788075 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I220119 10:30:28.789325 475 server/status/runtime.go:500  [n1] runtime stats: 254 MiB RSS, 250 goroutines, 102 MiB/97 MiB/226 MiB GO alloc/idle/total, 60 MiB/82 MiB CGO alloc/total, 113.0 CGO/sec, 0.2/0.4 %(u/s)time, 0.0 %gc (0x), 629 KiB/629 KiB (r/w)net
W220119 10:30:29.745279 142 storage/engine/rocksdb.go:2234  batch [1/57/0] commit took 954.491225ms (>= warning threshold 500ms)
W220119 10:30:29.746001 142 storage/store.go:3503  [n1,s1,r68/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:31.370187 126 storage/engine/rocksdb.go:2234  batch [1/49/0] commit took 1.611870966s (>= warning threshold 500ms)
W220119 10:30:31.370333 126 storage/store.go:3503  [n1,s1,r68/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
I220119 10:30:36.553335 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:30:36.553605 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 7.8s
W220119 10:30:36.553616 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:30:37.562135 124 storage/store.go:3503  [n1,s1,r89/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:40.647105 146 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 3.1s [applied=5, batches=1, state_assertions=0]
I220119 10:30:40.652975 475 server/status/runtime.go:500  [n1] runtime stats: 255 MiB RSS, 244 goroutines, 122 MiB/79 MiB/226 MiB GO alloc/idle/total, 60 MiB/82 MiB CGO alloc/total, 16.1 CGO/sec, 0.1/0.3 %(u/s)time, 0.0 %gc (0x), 1.2 MiB/1.2 MiB (r/w)net
W220119 10:30:42.519128 133 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:42.519563 126 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 1.9s [applied=2, batches=2, state_assertions=1]
W220119 10:30:42.519600 145 storage/store.go:3503  [n1,s1,r102/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:42.519697 142 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:42.519714 131 storage/store.go:3503  [n1,s1,r64/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W220119 10:30:43.617169 139 storage/store.go:3503  [n1,s1,r102/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:43.617215 124 storage/store.go:3503  [n1,s1,r48/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:43.617238 145 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:43.617264 125 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:43.617500 138 storage/store.go:3503  [n1,s1,r64/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:47.634508 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 7.0s
W220119 10:30:47.634526 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:30:47.634679 9007 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:30:47.634715 9005 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:30:47.634946 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:30:47.636869 144 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.0s [applied=2, batches=1, state_assertions=0]
W220119 10:30:47.637618 126 storage/store.go:3503  [n1,s1,r6/1:/Table/{SystemConâ€¦-11}] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:47.637677 139 storage/store.go:3503  [n1,s1,r102/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:47.638007 125 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:47.638362 145 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
W220119 10:30:47.638422 138 storage/store.go:3503  [n1,s1,r64/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
I220119 10:31:00.653069 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:31:00.653948 42 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:31:38.531671 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:31:38.531782 9131 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
W220119 10:31:38.532061 160 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W220119 10:31:38.532343 79 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:31:38.532539 9208 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:31:38.532612 9208 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:31:38.532849 9384 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I220119 10:31:38.532883 471 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (2/3 cur/max conns)
  3: ubuntu:23458 (1m32s: infos 20/117 sent/received, bytes 2795B/14366B sent/received)
  2: ubuntu:23457 (1m21s: infos 37/104 sent/received, bytes 4301B/12838B sent/received)
gossip server (0/3 cur/max conns, infos 858/2330 sent/received, bytes 323472B/374473B sent/received)
gossip connectivity
  n1 -> n2; n1 -> n3;
W220119 10:31:38.532899 9111 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I220119 10:31:38.532960 475 server/status/runtime.go:500  [n1] runtime stats: 264 MiB RSS, 260 goroutines, 139 MiB/66 MiB/230 MiB GO alloc/idle/total, 61 MiB/81 MiB CGO alloc/total, 4.6 CGO/sec, 0.1/0.0 %(u/s)time, 0.0 %gc (0x), 2.1 MiB/2.1 MiB (r/w)net
W220119 10:31:38.532985 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 50.9s
W220119 10:31:38.532993 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:31:38.533021 9388 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:31:38.533087 9285 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:31:38.533103 9217 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:31:38.533152 8978 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:31:38.533212 9130 storage/replica_range_lease.go:986  [n1,replicate,s1,r36/1:/Table/58/1/-92233497859711â€¦] have been waiting 1m0s attempting to acquire lease
I220119 10:31:38.533234 9130 storage/replica_range_lease.go:991  [n1,replicate,s1,r36/1:/Table/58/1/-92233497859711â€¦] slow lease acquisition finished after 1m32.155179819s with error [NotLeaseHolderError] r36: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:31:38.533273 9146 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:31:38.533302 9300 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:31:38.533315 9154 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
I220119 10:31:38.533323 9154 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 1m32.15371854s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
E220119 10:31:38.533353 9154 storage/queue.go:977  [n1,replicaGC,s1,r6/1:/Table/{SystemConâ€¦-11}] aborted during DistSender.Send: context deadline exceeded
W220119 10:31:38.533506 101 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:31:38.533758 9131 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 1m32.15384485s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:31:38.533845 9131 storage/node_liveness.go:523  [n1,s1,r36/1:/Table/58/1/-92233497859711â€¦] slow heartbeat took 92.2s
E220119 10:31:38.533851 9131 storage/replica_range_lease.go:292  [n1,s1,r36/1:/Table/58/1/-92233497859711â€¦] aborted during DistSender.Send: context canceled
I220119 10:31:38.534064 8482 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m38.422984591s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown after 1 attempts
W220119 10:31:38.534198 9285 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:31:38.534212 8978 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:31:38.536190 9146 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:31:38.536207 9300 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:31:38.594231 1159 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: show-version: operation "show cluster setting version" timed out after 2m0s
I220119 10:31:44.688770 9816 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:31:44.689539 9644 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:31:44.690000 482 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.2s
W220119 10:31:44.690008 482 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:31:44.702495 141 storage/store.go:3503  [n1,s1,r46/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 4.2s [applied=0, batches=0, state_assertions=0]
W220119 10:31:45.638652 125 storage/store.go:3503  [n1,s1,r53/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:31:45.639328 124 storage/store.go:3503  [n1,s1,r31/1:/Table/5{5-6}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
I220119 10:31:45.639805 9823 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:31:45.640121 141 storage/store.go:3503  [n1,s1,r46/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
I220119 10:31:45.641882 8411 storage/replica_write.go:208  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow command RequestLease [/Min,/Min) finished after 190.87s with error cannot replace lease repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 with repl=(n1,s1):1 seq=13 start=1642588106.058035933,1 exp=1642588123.768171179,0 pro=1642588114.768176570,0: proposed under invalid lease
I220119 10:31:45.641989 9007 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m0.80465333s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642120 153 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 3m10.873926795s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642249 9005 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m0.804256669s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642372 8742 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m53.936089061s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642457 8764 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m52.248455673s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642516 8856 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m32.30067713s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.642567 8955 storage/replica_range_lease.go:991  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] slow lease acquisition finished after 2m18.327858024s with error [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; current lease is repl=(n2,s2):2 seq=12 start=1642587279.141532061,1 exp=1642588308.557674956,0 pro=1642588299.557683863,0 after 1 attempts
I220119 10:31:45.647119 8572 storage/replica_write.go:208  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow command RequestLease [/System/NodeLiveness,/Min) finished after 174.02s with error cannot replace lease repl=(n3,s3):3 seq=13 start=1642587598.659721638,1 exp=1642588311.015919355,0 pro=1642588302.015926309,0 with repl=(n1,s1):1 seq=14 start=1642588104.850467270,1 exp=1642588140.629591419,0 pro=1642588131.629595827,0: proposed under invalid lease
I220119 10:31:45.647182 155 storage/replica_range_lease.go:991  [n1,s1,r2/1:/System/NodeLiveness{-Max}] slow lease acquisition finished after 2m20.713192405s with error [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; current lease is repl=(n3,s3):3 seq=13 start=1642587598.659721638,1 exp=1642588311.015919355,0 pro=1642588302.015926309,0 after 1 attempts
W220119 10:31:45.649295 9637 storage/node_liveness.go:523  [n1,s1,r86/1:/Table/58/1/-92233497859704â€¦] slow heartbeat took 7.1s
I220119 10:31:48.998825 475 server/status/runtime.go:500  [n1] runtime stats: 266 MiB RSS, 235 goroutines, 139 MiB/66 MiB/230 MiB GO alloc/idle/total, 63 MiB/83 MiB CGO alloc/total, 59.3 CGO/sec, 0.8/0.3 %(u/s)time, 0.0 %gc (0x), 1.3 MiB/1.3 MiB (r/w)net
I220119 10:31:49.003200 1165 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:31:49.900955 136 storage/store.go:3503  [n1,s1,r86/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W220119 10:31:49.902157 477 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:6}]}
