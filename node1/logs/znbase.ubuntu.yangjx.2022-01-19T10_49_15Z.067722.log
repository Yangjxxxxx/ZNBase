I220119 10:49:15.458289 1 util/log/clog.go:1194  [config] file created at: 2022/01/19 10:49:15
I220119 10:49:15.458289 1 util/log/clog.go:1194  [config] running on machine: ubuntu
I220119 10:49:15.458289 1 util/log/clog.go:1194  [config] binary: ZNBaseDB OSS 4cd474b8 (x86_64-linux-gnu, built 2022/01/19 10:46:53, go1.14)
I220119 10:49:15.458289 1 util/log/clog.go:1194  [config] arguments: [./znbase start --insecure --store=./node1 --listen-addr=:23456 --http-addr=:8000 --join=:23456,:23457,:23458]
I220119 10:49:15.458289 1 util/log/clog.go:1194  line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=âœ“
I220119 10:49:15.458288 1 cli/start.go:1156  logging to directory /home/yangjx/go/src/github.com/znbasedb/znbase/node1/logs
W220119 10:49:15.460907 1 cli/start.go:1191  RUNNING IN INSECURE MODE!

- Your cluster is open for any client that can access <all your IP addresses>.
- Any user, even root, can log in without providing a password.
- Any user, connecting as root, can read or write any data in your cluster.
- There is no network encryption nor authentication, and thus no confidentiality.

Check out how to secure your cluster: official docs about version 4cd474b8
I220119 10:49:15.461170 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
W220119 10:49:15.461228 1 cli/start.go:1067  Using the default setting for --cache (128 MiB).
  A significantly larger value is usually needed for good performance.
  If you have a dedicated server a reasonable setting is --cache=.25 (976 MiB).
I220119 10:49:15.461341 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
W220119 10:49:15.461444 1 cli/start.go:1080  Using the default setting for --max-sql-memory (128 MiB).
  A significantly larger value is usually needed in production.
  If you have a dedicated server a reasonable setting is --max-sql-memory=.25 (976 MiB).
I220119 10:49:15.461614 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:49:15.461687 1 cli/start.go:1205  ZNBaseDB OSS 4cd474b8 (x86_64-linux-gnu, built 2022/01/19 10:46:53, go1.14)
I220119 10:49:15.469570 1 server/status/recorder.go:610  available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:49:15.469598 1 server/config.go:400  system total memory: 3.8 GiB
I220119 10:49:15.469638 1 server/config.go:402  server configuration:
max offset             500000000
cache size             128 MiB
SQL memory pool size   128 MiB
scan interval          10m0s
scan min idle time     10ms
scan max idle time     1s
event log enabled      true
I220119 10:49:15.469649 1 cli/start.go:1045  using local environment variables: GODEBUG=cgocheck=0
I220119 10:49:15.469658 1 cli/start.go:1052  process identity: uid 1000 euid 1000 gid 1000 egid 1000
I220119 10:49:15.469664 1 cli/start.go:676  starting znbase node
I220119 10:49:15.470668 37 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-temp723566940"
I220119 10:49:15.497960 37 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-cursor-temp380064011"
I220119 10:49:15.525108 37 server/server.go:1008  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
W220119 10:49:15.525408 37 server/config_unix.go:92  soft open file descriptor limit 4096 is under the recommended limit 15000; this may decrease performance
please see official docs about version 4cd474b8 for more details
I220119 10:49:15.525497 37 storage/engine/rocksdb.go:721  opening rocksdb instance at "/home/yangjx/go/src/github.com/znbasedb/znbase/node1"
I220119 10:49:15.801880 37 server/config.go:509  [n?] 1 storage engine initialized
I220119 10:49:15.801900 37 server/config.go:512  [n?] rocksdb cache size: 128 MiB
I220119 10:49:15.801909 37 server/config.go:512  [n?] store 0: rocksdb, max size 0 B, max open file limit 3840
W220119 10:49:15.803560 37 gossip/gossip.go:1508  [n?] no incoming or outgoing connections
I220119 10:49:15.805360 37 server/server.go:1058  [n?] Sleeping till wall time 1642589355805339387 to catches up to 1642589356025045739 to ensure monotonicity. Delta: 219.706352ms
I220119 10:49:15.810340 59 gossip/client.go:128  [n?] started gossip client to ubuntu:23457
I220119 10:49:15.814070 41 gossip/gossip.go:920  [n?] MaxPeers Recomputed as 3
I220119 10:49:15.814127 41 gossip/gossip.go:920  [n?] MaxPeers Recomputed as 3
I220119 10:49:16.025683 37 gossip/gossip.go:397  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"ubuntu:23456" > attrs:<> locality:<> ServerVersion:<major_val:19 minor_val:1 patch:0 unstable:10 > build_tag:"4cd474b8" started_at:1642589356025559121 location_name:<> 
I220119 10:49:16.029448 41 gossip/gossip.go:920  [n1] MaxPeers Recomputed as 3
I220119 10:49:16.084459 37 server/node.go:457  [n1] initialized store [n1,s1]: disk (capacity=78 GiB, available=35 GiB, used=32 MiB, logicalBytes=59 MiB), ranges=107, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=35172.00 p50=524279.00 p75=524293.00 p90=524301.00 pMax=21339996.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I220119 10:49:16.084603 37 storage/stores.go:238  [n1] read 2 node addresses from persistent storage
I220119 10:49:16.084742 37 server/node.go:695  [n1] connecting to gossip network to verify cluster ID...
I220119 10:49:16.084759 37 server/node.go:715  [n1] node connected via gossip and verified as part of cluster "3bbb8c74-c606-434f-b2eb-5e4523c470ba"
I220119 10:49:16.084817 37 server/node.go:538  [n1] node=1: started with [<no-attributes>=/home/yangjx/go/src/github.com/znbasedb/znbase/node1] engine(s) and attributes []
I220119 10:49:16.084989 37 server/status/recorder.go:610  [n1] available memory from cgroups (8.0 EiB) exceeds system memory 3.8 GiB, using system memory
I220119 10:49:16.085043 37 server/server.go:1730  [n1] starting http server at [::]:8000 (use: ubuntu:8000)
I220119 10:49:16.085052 37 server/server.go:1732  [n1] starting grpc/postgres server at [::]:23456
I220119 10:49:16.085062 37 server/server.go:1733  [n1] advertising ZNBaseDB node at ubuntu:23456
W220119 10:49:49.197574 63 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:49:49.198308 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 33.1s
W220119 10:49:49.198329 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted in distSender: context deadline exceeded
W220119 10:49:49.198561 94 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
I220119 10:49:49.199167 468 server/status/runtime.go:500  [n1] runtime stats: 144 MiB RSS, 221 goroutines, 0 B/0 B/0 B GO alloc/idle/total, 13 MiB/17 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (7x), 1.0 MiB/1.0 MiB (r/w)net
W220119 10:49:49.199298 63 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:49:49.200611 105 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:49:49.200683 30 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:49:49.200722 111 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:49:49.200779 179 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:49:49.200801 104 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:49:49.200936 179 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:49:49.200999 111 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:49:49.202446 211 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:49:49.202501 189 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:49:49.202557 211 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:49:49.202583 189 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:49:49.203270 534 cli/start.go:666  The server appears to be unable to contact the other nodes in the cluster. Please try:

- starting the other nodes, if you haven't already;
- double-checking that the '--join' and '--listen'/'--advertise' flags are set up correctly;
- running the 'znbase init' command if you are trying to initialize a new cluster.

If problems persist, please see official docs about version 4cd474b8.
W220119 10:49:49.206154 31 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I220119 10:49:49.206597 537 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:49:49.295155 143 storage/queue.go:468  [n1,s1,r2/1:/System/NodeLiveness{-Max}] rate limited in MaybeAdd (raftlog): throttled on async limiting semaphore
W220119 10:49:50.811758 520 storage/node_liveness.go:523  [n1,s1,r41/1:/Table/5{7/1/-922â€¦-8}] slow heartbeat took 33.7s
W220119 10:49:50.812116 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 1.6s
I220119 10:49:50.812276 475 storage/node_liveness.go:453  [n1,hb] heartbeat failed on epoch increment; retrying
I220119 10:49:51.128405 37 server/server.go:1802  [n1] done ensuring all necessary migrations have run
I220119 10:49:51.128423 37 server/server.go:1805  [n1] serving sql connections
I220119 10:49:51.128630 37 cli/start.go:813  [config] clusterID: 3bbb8c74-c606-434f-b2eb-5e4523c470ba
I220119 10:49:51.128650 37 cli/start.go:821  node startup completed:
ZNBaseDB node starting at 2022-01-19 10:49:51.128497417 +0000 UTC (took 35.7s)
build:               OSS 4cd474b8 @ 2022/01/19 10:46:53 (go1.14)
webui:               http://ubuntu:8000
sql:                 postgresql://root@ubuntu:23456?sslmode=disable
client flags:        ./znbase <client cmd> --host=ubuntu:23456 --insecure
logs:                /home/yangjx/go/src/github.com/znbasedb/znbase/node1/logs
temp dir:            /home/yangjx/go/src/github.com/znbasedb/znbase/node1/znbase-temp723566940
external I/O path:   /home/yangjx/go/src/github.com/znbasedb/znbase/node1/extern
store[0]:            path=/home/yangjx/go/src/github.com/znbasedb/znbase/node1,state=ENABLE
storage engine:      rocksdb
status:              restarted pre-existing node
clusterID:           3bbb8c74-c606-434f-b2eb-5e4523c470ba
nodeID:              1
I220119 10:49:51.133386 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:49:51.133399 859 security/audit/task/runner.go:216  [n1] audit_server_71fbb202-7915-11ec-8f59-000c29793ffc monitor workers every 5 seconds
I220119 10:49:51.133405 858 security/audit/task/runner.go:284  [n1] audit_server_71fbb202-7915-11ec-8f59-000c29793ffc init, min:3, max:30
I220119 10:49:51.484365 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:49:51.484765 91 storage/stores.go:257  [n1] wrote 2 node addresses to persistent storage
I220119 10:49:51.757028 840 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:49:51.771596 917 sql/lease.go:2613  released orphaned table lease: {id:58 version:1 expiration:{Time:{wall:46676000 ext:63778185130 loc:<nil>}}}
I220119 10:49:51.780451 916 sql/lease.go:2613  released orphaned table lease: {id:57 version:1 expiration:{Time:{wall:692044000 ext:63778185111 loc:<nil>}}}
I220119 10:49:51.793624 886 sql/event_log.go:235  [n1] Event: "node_restart", target: 1, info: nodeID:1, lastUp:1642588305649156464, ClusterID:3bbb8c74-c606-434f-b2eb-5e4523c470ba
E220119 10:49:51.821288 867 server/server.go:1869  [n1,client=127.0.0.1:35456] write tcp 127.0.0.1:23456->127.0.0.1:35456: write: broken pipe
I220119 10:49:51.885168 884 sql/event_log.go:235  [n1] Event: "user_login", target: 1, info: User name:root  Client Info:127.0.0.1:35456  Login time:2022-01-19 10:49:51.820957526 +0000 UTC
I220119 10:49:51.885625 885 sql/event_log.go:235  [n1] Event: "user_logout", target: 1, info: User name:root  Client Info:127.0.0.1:35456  Logout time:2022-01-19 10:49:51.821241644 +0000 UTC
I220119 10:49:52.799558 840 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:49:53.355923 899 storage/replica_raftstorage.go:817  [n1,s1,r4/1:/System{/tsd-tse}] applying RAFT snapshot at index 5713 (id=0ae5603d, encoded size=16747382, 64 rocksdb batches, 0 log entries)
I220119 10:49:53.505750 899 storage/replica_raftstorage.go:823  [n1,s1,r4/1:/System{/tsd-tse}] applied RAFT snapshot in 150ms [clear=6ms batch=71ms entries=0ms commit=72ms]
I220119 10:49:54.206630 886 sql/event_log.go:235  [n1] Event: "user_login", target: 1, info: User name:root  Client Info:127.0.0.1:35482  Login time:2022-01-19 10:49:54.162714521 +0000 UTC
I220119 10:49:54.222670 884 sql/event_log.go:235  [n1] Event: "set_var", target: 0, info: User name:root SHOW SYNTAX:SET sql_safe_updates = true
I220119 10:49:54.860797 840 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:49:56.087722 175 storage/store.go:4034  [n1,s1] sstables (read amplification = 2):
0 [ 473K 1 ]: 473K
6 [  20M 3 ]: 15M 3M 2M
I220119 10:49:56.087787 175 storage/store.go:4035  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0   473.48 KB   0.5      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      5.4      0.09              0.00         1    0.086       0      0
  L6      3/0   19.86 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      4/0   20.32 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      5.4      0.09              0.00         1    0.086       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      5.4      0.09              0.00         1    0.086       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      5.4      0.09              0.00         1    0.086       0      0
Uptime(secs): 40.6 total, 40.6 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.01 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.1 seconds
Interval compaction: 0.00 GB write, 0.01 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.1 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
I220119 10:49:59.202407 468 server/status/runtime.go:500  [n1] runtime stats: 323 MiB RSS, 226 goroutines, 163 MiB/39 MiB/221 MiB GO alloc/idle/total, 45 MiB/53 MiB CGO alloc/total, 1031.8 CGO/sec, 2.7/5.0 %(u/s)time, 0.0 %gc (2x), 3.8 MiB/3.8 MiB (r/w)net
I220119 10:49:59.371799 840 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:50:01.136254 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:50:01.146935 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W220119 10:50:10.653387 91 gossip/gossip.go:1513  [n1] first range unavailable; trying remaining resolvers
I220119 10:50:10.654657 1217 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:50:15.144509 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:50:15.144562 713 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:15.144610 716 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:15.144987 605 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:50:15.145042 720 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:50:15.145312 678 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:50:15.145452 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:50:15.145549 678 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:50:15.146479 468 server/status/runtime.go:500  [n1] runtime stats: 267 MiB RSS, 231 goroutines, 180 MiB/23 MiB/221 MiB GO alloc/idle/total, 45 MiB/53 MiB CGO alloc/total, 19.3 CGO/sec, 0.4/0.6 %(u/s)time, 0.0 %gc (0x), 728 KiB/728 KiB (r/w)net
W220119 10:50:15.148398 748 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:15.148839 710 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
I220119 10:50:15.149742 1242 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
I220119 10:50:15.149756 1242 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:50:15.149764 1242 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
W220119 10:50:15.151201 693 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:50:15.151647 1181 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
I220119 10:50:15.151656 1181 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:50:15.151663 1181 rpc/nodedialer/nodedialer.go:149  [n1,intExec=read-setting,txn=4fd72ff0] unable to connect to n3: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
W220119 10:50:15.153310 91 gossip/gossip.go:1508  [n1] no incoming or outgoing connections
W220119 10:50:15.153493 698 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:50:15.153504 1259 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
I220119 10:50:15.153525 1259 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:50:15.153531 1259 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to check for ready connection to n2 at ubuntu:23457: connection not ready: TRANSIENT_FAILURE
W220119 10:50:15.153525 720 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:15.153536 698 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:15.153581 693 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:15.153515 605 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:50:17.265862 475 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:50:17.265880 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 6.6s
W220119 10:50:17.265937 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:50:17.266609 153 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.1s [applied=2, batches=1, state_assertions=0]
I220119 10:50:17.269388 1286 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:50:20.385034 153 storage/engine/rocksdb.go:2234  batch [1505/171288/3] commit took 3.115817053s (>= warning threshold 500ms)
W220119 10:50:20.385236 149 storage/store.go:3503  [n1,s1,r107/1:/Table/58/1/-92233497859701â€¦] handle raft ready: 5.2s [applied=2, batches=2, state_assertions=1]
W220119 10:50:20.385298 153 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 3.1s [applied=3, batches=1, state_assertions=0]
W220119 10:50:20.385589 140 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 3.1s [applied=2, batches=2, state_assertions=1]
I220119 10:50:20.386699 1279 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
I220119 10:50:20.387203 1277 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I220119 10:50:22.325124 176 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  0: ubuntu:23458 (4s: infos 0/0 sent/received, bytes 0B/0B sent/received)
gossip server (0/3 cur/max conns, infos 109/195 sent/received, bytes 67654B/74165B sent/received)
gossip connectivity
I220119 10:50:22.326007 1324 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:50:22.326262 1280 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:50:22.327223 144 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 1.9s [applied=4, batches=4, state_assertions=2]
I220119 10:50:22.327460 1316 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:50:22.327773 141 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=10, batches=5, state_assertions=2]
W220119 10:50:22.328711 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.1s
W220119 10:50:22.328726 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:50:23.077587 147 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.078205 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.946157055e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W220119 10:50:23.079800 139 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.080167 145 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.080473 160 storage/store.go:3503  [n1,s1,r36/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.080551 137 storage/store.go:3503  [n1,s1,r39/1:/Table/57/1/-9223349785974â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.080621 149 storage/store.go:3503  [n1,s1,r107/1:/Table/58/1/-92233497859701â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.080677 143 storage/store.go:3503  [n1,s1,r8/1:/Table/1{2-3}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:23.081196 156 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
W220119 10:50:23.082011 148 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.5s [applied=2, batches=1, state_assertions=0]
I220119 10:50:24.483421 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:50:25.299263 156 storage/store.go:3503  [n1,s1,r51/1:/Table/58/1/-922334978597â€¦] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I220119 10:50:25.458671 468 server/status/runtime.go:500  [n1] runtime stats: 261 MiB RSS, 229 goroutines, 180 MiB/23 MiB/221 MiB GO alloc/idle/total, 45 MiB/53 MiB CGO alloc/total, 56.1 CGO/sec, 1.3/0.7 %(u/s)time, 0.0 %gc (1x), 4.7 MiB/4.7 MiB (r/w)net
I220119 10:50:25.625474 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:50:26.335123 159 storage/engine/rocksdb.go:2234  batch [1509/171393/4] commit took 555.758206ms (>= warning threshold 500ms)
W220119 10:50:26.335325 159 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.6s [applied=4, batches=1, state_assertions=0]
W220119 10:50:26.335767 155 storage/store.go:3503  [n1,s1,r94/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.6s [applied=1, batches=1, state_assertions=0]
W220119 10:50:26.700771 152 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:50:26.700837 153 storage/store.go:3503  [n1,s1,r97/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:50:26.978559 157 storage/engine/rocksdb.go:2234  batch [5/57803/0] commit took 641.283561ms (>= warning threshold 500ms)
W220119 10:50:26.978587 155 storage/store.go:3503  [n1,s1,r28/1:/Table/5{1-3}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.010064 143 storage/store.go:3503  [n1,s1,r14/1:/Table/1{8-9}] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W220119 10:50:27.010127 138 storage/store.go:3503  [n1,s1,r95/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 1.2s [applied=1, batches=1, state_assertions=0]
W220119 10:50:27.010493 157 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.7s [applied=4, batches=1, state_assertions=0]
W220119 10:50:27.561832 157 storage/store.go:3503  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.561996 143 storage/store.go:3503  [n1,s1,r37/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.562074 146 storage/store.go:3503  [n1,s1,r95/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.563161 144 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.564217 137 storage/store.go:3503  [n1,s1,r38/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.564393 152 storage/store.go:3503  [n1,s1,r97/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.564434 151 storage/store.go:3503  [n1,s1,r91/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.564496 138 storage/store.go:3503  [n1,s1,r90/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:27.564622 145 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:50:30.601918 145 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.3s [applied=3, batches=2, state_assertions=1]
W220119 10:50:30.622241 140 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 2.4s [applied=2, batches=2, state_assertions=1]
W220119 10:50:30.623485 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.4s
W220119 10:50:31.430674 139 storage/store.go:3503  [n1,s1,r66/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.430742 137 storage/store.go:3503  [n1,s1,r103/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.430900 150 storage/store.go:3503  [n1,s1,r78/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.431022 138 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W220119 10:50:31.432319 158 storage/store.go:3503  [n1,s1,r17/1:/Table/2{1-2}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.432370 140 storage/store.go:3503  [n1,s1,r65/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.437452 156 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.437524 157 storage/store.go:3503  [n1,s1,r80/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.437553 147 storage/store.go:3503  [n1,s1,r6/1:/Table/{SystemConâ€¦-11}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.437629 146 storage/store.go:3503  [n1,s1,r44/1:/Table/58/1/-9223349785971â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W220119 10:50:31.437665 151 storage/store.go:3503  [n1,s1,r56/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
I220119 10:50:51.090235 468 server/status/runtime.go:500  [n1] runtime stats: 262 MiB RSS, 227 goroutines, 99 MiB/106 MiB/230 MiB GO alloc/idle/total, 46 MiB/53 MiB CGO alloc/total, 23.6 CGO/sec, 0.2/0.3 %(u/s)time, 0.0 %gc (0x), 5.5 MiB/5.5 MiB (r/w)net
I220119 10:50:51.091201 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:50:51.092007 138 storage/store.go:3503  [n1,s1,r12/1:/Table/1{6-7}] handle raft ready: 13.6s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.092269 1298 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:51.092303 1299 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:51.092356 1260 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:51.092410 1286 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:50:51.092698 1318 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:50:51.092801 1291 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:50:51.092996 1318 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:51.093014 1291 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:51.093156 94 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:50:51.093362 91 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:50:51.095621 1671 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:50:51.095723 1672 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:50:51.097033 1670 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:50:51.775687 158 storage/store.go:3503  [n1,s1,r60/1:/Table/58/1/-92233497859708â€¦] handle raft ready: 14.3s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.775728 143 storage/store.go:3503  [n1,s1,r17/1:/Table/2{1-2}] handle raft ready: 14.3s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.776289 1681 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Unavailable desc = transport is closing
W220119 10:50:51.776805 152 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 14.3s [applied=4, batches=1, state_assertions=0]
W220119 10:50:51.776877 147 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 14.3s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.778437 160 storage/store.go:3503  [n1,s1,r18/1:/Table/2{2-3}] handle raft ready: 14.3s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.778486 145 storage/store.go:3503  [n1,s1,r10/1:/Table/1{4-5}] handle raft ready: 14.3s [applied=0, batches=0, state_assertions=0]
W220119 10:50:51.778790 1348 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:50:51.779047 1343 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:50:51.780556 1682 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n3] tripped: failed to check for ready connection to n3 at ubuntu:23458: connection not ready: TRANSIENT_FAILURE
I220119 10:50:51.780639 1682 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerTripped
I220119 10:50:51.781667 1667 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
W220119 10:50:51.781889 1680 storage/raft_transport.go:620  [n1] creating batch client for node 2 failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:50:51.781950 1348 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:50:51.781996 1343 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:50:54.346125 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:50:54.362306 1733 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n3] event: BreakerReset
W220119 10:50:54.363624 148 storage/engine/rocksdb.go:2234  batch [1510/171412/4] commit took 2.585095238s (>= warning threshold 500ms)
W220119 10:50:54.363750 148 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 16.9s [applied=4, batches=1, state_assertions=0]
W220119 10:50:56.714884 157 storage/engine/rocksdb.go:2234  batch [2/163/2] commit took 2.351062431s (>= warning threshold 500ms)
W220119 10:50:56.715249 157 storage/store.go:3503  [n1,s1,r103/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 5.6s [applied=2, batches=2, state_assertions=1]
W220119 10:50:56.717332 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.6s
W220119 10:50:56.717345 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:50:58.737220 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 2.0s
W220119 10:50:58.738564 144 storage/store.go:3503  [n1,s1,r13/1:/Table/1{7-8}] handle raft ready: 2.0s [applied=2, batches=2, state_assertions=1]
W220119 10:50:58.740417 138 storage/store.go:3503  [n1,s1,r17/1:/Table/2{1-2}] handle raft ready: 2.0s [applied=3, batches=2, state_assertions=1]
W220119 10:50:58.740679 137 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 2.0s [applied=5, batches=1, state_assertions=0]
W220119 10:50:58.740715 146 storage/store.go:3503  [n1,s1,r48/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W220119 10:50:58.740808 149 storage/store.go:3503  [n1,s1,r85/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W220119 10:50:59.248174 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:3.221225471e+09} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W220119 10:50:59.257533 157 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:00.525037 133 storage/store.go:3503  [n1,s1,r10/1:/Table/1{4-5}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:51:00.525374 154 storage/store.go:3503  [n1,s1,r17/1:/Table/2{1-2}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:00.525413 156 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:00.525457 146 storage/store.go:3503  [n1,s1,r39/1:/Table/57/1/-9223349785974â€¦] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W220119 10:51:01.058493 143 storage/engine/rocksdb.go:2234  batch [3766/428209/7] commit took 533.128913ms (>= warning threshold 500ms)
W220119 10:51:01.058656 143 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.3s [applied=8, batches=1, state_assertions=0]
W220119 10:51:01.059653 148 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 0.5s [applied=2, batches=2, state_assertions=1]
W220119 10:51:01.403083 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:3.221225471e+09}]}
W220119 10:51:01.405056 156 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 0.9s [applied=2, batches=1, state_assertions=0]
I220119 10:51:01.405555 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
I220119 10:51:01.415860 468 server/status/runtime.go:500  [n1] runtime stats: 266 MiB RSS, 232 goroutines, 146 MiB/63 MiB/230 MiB GO alloc/idle/total, 46 MiB/55 MiB CGO alloc/total, 54.0 CGO/sec, 0.9/0.4 %(u/s)time, 0.0 %gc (0x), 2.7 MiB/2.7 MiB (r/w)net
W220119 10:51:01.583328 148 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:01.583922 143 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.5s [applied=3, batches=1, state_assertions=0]
W220119 10:51:03.388648 150 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 1.3s [applied=2, batches=2, state_assertions=1]
W220119 10:51:03.390359 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:1.946157055e+09}]}
W220119 10:51:05.705877 144 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:05.705935 156 storage/store.go:3503  [n1,s1,r20/1:/Table/2{4-5}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:08.115487 156 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.4s [applied=4, batches=2, state_assertions=1]
W220119 10:51:09.228628 152 storage/engine/rocksdb.go:2234  batch [1510/171435/0] commit took 1.103150895s (>= warning threshold 500ms)
W220119 10:51:09.228764 152 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.1s [applied=4, batches=1, state_assertions=0]
W220119 10:51:09.231539 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 3.5s
W220119 10:51:09.233981 154 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 1.1s [applied=2, batches=2, state_assertions=1]
W220119 10:51:09.234110 142 storage/store.go:3503  [n1,s1,r66/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 1.1s [applied=1, batches=1, state_assertions=0]
W220119 10:51:09.234181 138 storage/store.go:3503  [n1,s1,r95/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W220119 10:51:09.234392 150 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W220119 10:51:09.234589 159 storage/store.go:3503  [n1,s1,r75/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
I220119 10:51:09.300828 840 server/server_update.go:64  [n1] failed attempt to upgrade cluster version, error: node 4 not running (DEAD), cannot determine version
I220119 10:51:17.556634 176 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  3: ubuntu:23458 (26s: infos 23/81 sent/received, bytes 5251B/11413B sent/received)
gossip server (0/3 cur/max conns, infos 197/465 sent/received, bytes 84219B/113172B sent/received)
W220119 10:51:17.556679 91 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:51:17.556841 1967 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:51:17.558851 468 server/status/runtime.go:500  [n1] runtime stats: 267 MiB RSS, 239 goroutines, 164 MiB/47 MiB/230 MiB GO alloc/idle/total, 46 MiB/55 MiB CGO alloc/total, 27.3 CGO/sec, 0.3/0.4 %(u/s)time, 0.0 %gc (0x), 3.3 MiB/3.3 MiB (r/w)net
W220119 10:51:19.232546 1733 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:51:19.232667 1685 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:19.232697 1713 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:51:19.232722 1685 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:19.232792 1749 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:19.232859 1744 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:19.233034 1732 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: EOF:
W220119 10:51:20.716278 1674 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:20.716721 1749 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:20.716736 1744 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:20.717926 1720 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:20.718083 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:51:20.718171 2004 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 tripped: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:51:20.718180 2004 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerTripped
W220119 10:51:20.718198 2004 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23458: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
W220119 10:51:20.718253 1674 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:20.718849 470 server/node.go:876  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:round-trip-latency-p90 Value:2.415919103e+09}]}
I220119 10:51:20.719344 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:51:20.719855 146 storage/store.go:3503  [n1,s1,r12/1:/Table/1{6-7}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:35.985802 152 storage/store.go:3503  [n1,s1,r20/1:/Table/2{4-5}] handle raft ready: 15.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:35.985844 147 storage/store.go:3503  [n1,s1,r90/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 15.3s [applied=0, batches=0, state_assertions=0]
W220119 10:51:35.985919 1714 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
I220119 10:51:35.986242 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:51:35.986341 1720 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:35.986384 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:51:37.518598 2014 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:51:37.518724 2034 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I220119 10:51:37.518731 2034 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:51:37.518738 2034 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W220119 10:51:37.519632 173 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:51:37.519827 475 storage/node_liveness.go:775  [n1,hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W220119 10:51:37.519840 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 20.0s
W220119 10:51:37.519853 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W220119 10:51:37.519917 2014 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:37.520103 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:51:37.521569 2010 storage/raft_transport.go:620  [n1] creating batch client for node 3 failed: rpc error: code = Canceled desc = grpc: the client connection is closing
W220119 10:51:37.521914 1992 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:37.522900 1720 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing
I220119 10:51:37.958005 468 server/status/runtime.go:500  [n1] runtime stats: 267 MiB RSS, 192 goroutines, 170 MiB/41 MiB/230 MiB GO alloc/idle/total, 46 MiB/55 MiB CGO alloc/total, 1.9 CGO/sec, 0.1/0.0 %(u/s)time, 0.0 %gc (0x), 457 KiB/457 KiB (r/w)net
W220119 10:51:37.958432 1992 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:51:37.958467 2047 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 tripped: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:51:37.958472 2047 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerTripped
W220119 10:51:37.958484 2047 gossip/client.go:122  [n1] failed to start gossip client to ubuntu:23457: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:51:37.958531 1976 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:23456 [n2] tripped: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:51:37.958534 1976 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerTripped
I220119 10:51:37.958539 1976 rpc/nodedialer/nodedialer.go:149  [n1] unable to connect to n2: failed to connect to n2 at ubuntu:23457: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing cannot reuse client connection"
I220119 10:51:37.959938 2100 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23458 event: BreakerReset
I220119 10:51:37.959951 2100 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:51:37.963226 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:51:39.462029 2229 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:51:42.928130 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:51:42.928303 155 storage/store.go:3503  [n1,s1,r43/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:42.928512 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.4s
W220119 10:51:42.928522 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:51:42.928678 153 storage/store.go:3503  [n1,s1,r91/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:42.928712 147 storage/store.go:3503  [n1,s1,r79/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:42.928744 141 storage/store.go:3503  [n1,s1,r80/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:42.928756 137 storage/store.go:3503  [n1,s1,r96/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
I220119 10:51:42.928766 2249 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:23456 [n2] event: BreakerReset
W220119 10:51:42.928776 149 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
I220119 10:51:42.928862 2076 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:51:43.195825 152 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W220119 10:51:49.584917 91 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
W220119 10:51:49.585245 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I220119 10:51:50.958015 468 server/status/runtime.go:500  [n1] runtime stats: 268 MiB RSS, 224 goroutines, 170 MiB/41 MiB/230 MiB GO alloc/idle/total, 46 MiB/55 MiB CGO alloc/total, 9.3 CGO/sec, 0.2/0.2 %(u/s)time, 0.0 %gc (0x), 900 KiB/900 KiB (r/w)net
I220119 10:51:50.958236 2173 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:51:50.958377 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 8.0s
W220119 10:51:50.958384 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:51:50.959418 2187 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:51:50.959458 2196 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:50.959474 2229 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:51:50.959617 2083 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:50.959643 2196 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:50.959663 2083 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:51:50.959685 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:51:50.960312 2102 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:51:50.960335 2054 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:51:50.960869 2102 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:51:52.057124 142 storage/engine/rocksdb.go:2234  batch [1/57/0] commit took 7.765336109s (>= warning threshold 500ms)
W220119 10:51:52.983091 150 storage/engine/rocksdb.go:2234  batch [21/825/0] commit took 924.840028ms (>= warning threshold 500ms)
W220119 10:51:52.983358 154 storage/store.go:3503  [n1,s1,r6/1:/Table/{SystemConâ€¦-11}] handle raft ready: 9.8s [applied=1, batches=1, state_assertions=0]
W220119 10:51:52.983958 142 storage/store.go:3503  [n1,s1,r80/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 9.8s [applied=0, batches=0, state_assertions=0]
I220119 10:51:52.984163 2355 vendor/github.com/znbasedb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:23456->ubuntu:23457 event: BreakerReset
I220119 10:51:52.984174 2355 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:51:52.984469 159 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984511 150 storage/store.go:3503  [n1,s1,r96/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 9.8s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984560 157 storage/store.go:3503  [n1,s1,r53/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984593 160 storage/store.go:3503  [n1,s1,r68/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984619 144 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984672 140 storage/store.go:3503  [n1,s1,r38/1:/Table/57/1/-92233497859743â€¦] handle raft ready: 2.0s [applied=1, batches=1, state_assertions=0]
W220119 10:51:52.984687 145 storage/store.go:3503  [n1,s1,r72/1:/Table/58/1/-92233497859706â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984698 155 storage/store.go:3503  [n1,s1,r45/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984875 151 storage/store.go:3503  [n1,s1,r13/1:/Table/1{7-8}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984892 147 storage/store.go:3503  [n1,s1,r70/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984906 143 storage/store.go:3503  [n1,s1,r10/1:/Table/1{4-5}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984920 146 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984982 141 storage/store.go:3503  [n1,s1,r36/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.984998 158 storage/store.go:3503  [n1,s1,r104/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.985250 148 storage/store.go:3503  [n1,s1,r8/1:/Table/1{2-3}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.985269 156 storage/store.go:3503  [n1,s1,r57/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:52.985285 152 storage/store.go:3503  [n1,s1,r66/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:51:54.581475 144 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 1.6s [applied=1, batches=1, state_assertions=0]
I220119 10:51:54.581840 2361 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:52:07.759177 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:52:07.759401 142 storage/store.go:3503  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 13.2s [applied=2, batches=1, state_assertions=0]
W220119 10:52:07.759918 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:52:07.761320 2238 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:07.762371 2293 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:07.762707 153 storage/store.go:3503  [n1,s1,r91/1:/Table/58/1/-92233497859704â€¦] handle raft ready: 13.2s [applied=2, batches=1, state_assertions=0]
W220119 10:52:07.762733 143 storage/store.go:3503  [n1,s1,r34/1:/Table/57{-/1/-9223â€¦}] handle raft ready: 13.2s [applied=1, batches=1, state_assertions=0]
W220119 10:52:07.762735 159 storage/store.go:3503  [n1,s1,r43/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 13.2s [applied=3, batches=1, state_assertions=0]
W220119 10:52:07.762758 150 storage/store.go:3503  [n1,s1,r6/1:/Table/{SystemConâ€¦-11}] handle raft ready: 13.2s [applied=1, batches=1, state_assertions=0]
W220119 10:52:07.762759 139 storage/store.go:3503  [n1,s1,r79/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 13.2s [applied=2, batches=1, state_assertions=0]
W220119 10:52:07.762894 2297 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I220119 10:52:07.762896 2259 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:52:07.762929 2297 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:07.763594 149 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 13.2s [applied=15, batches=13, state_assertions=7]
W220119 10:52:09.065903 2249 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:09.066106 1948 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:09.066379 154 storage/store.go:3503  [n1,s1,r107/1:/Table/58/1/-92233497859701â€¦] handle raft ready: 16.1s [applied=1, batches=1, state_assertions=0]
W220119 10:52:09.068653 2339 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:09.068742 2313 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:09.069317 94 storage/closedts/provider/provider.go:156  [ct-closer] unable to move closed timestamp forward: not live
W220119 10:52:09.071418 2239 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: EOF:
W220119 10:52:09.071585 2339 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:09.071798 1948 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:09.072643 2313 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:12.016962 160 storage/engine/rocksdb.go:2234  batch [753/85689/2] commit took 938.80337ms (>= warning threshold 500ms)
W220119 10:52:12.017195 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 21.1s
W220119 10:52:12.017208 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:52:12.017214 160 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 17.4s [applied=1, batches=1, state_assertions=0]
I220119 10:52:12.017955 468 server/status/runtime.go:500  [n1] runtime stats: 269 MiB RSS, 216 goroutines, 183 MiB/28 MiB/230 MiB GO alloc/idle/total, 46 MiB/55 MiB CGO alloc/total, 27.3 CGO/sec, 0.1/0.2 %(u/s)time, 0.0 %gc (0x), 618 KiB/618 KiB (r/w)net
I220119 10:52:13.378225 2491 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
I220119 10:52:13.378383 2546 gossip/client.go:128  [n1] started gossip client to ubuntu:23458
I220119 10:52:13.945184 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
I220119 10:52:17.772609 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:52:18.714480 46 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23456 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
W220119 10:52:18.741855 1853 storage/replica_write.go:191  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 61.18s for proposing command RequestLease [/System/NodeLiveness,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/2

and the following Raft status: {"id":"1","term":18,"vote":"0","commit":12122,"lead":"2","raftState":"StateFollower","applied":12119,"progress":{},"leadtransferee":"0"}
W220119 10:52:18.742878 168 storage/replica_range_lease.go:986  [n1,s1,r2/1:/System/NodeLiveness{-Max}] have been waiting 1m0s attempting to acquire lease
E220119 10:52:18.744013 1970 storage/queue.go:977  [n1,replicaGC,s1,r79/1:/Table/58/1/-92233497859705â€¦] aborted during DistSender.Send: context deadline exceeded
I220119 10:52:18.744128 2461 internal/client/txn.go:759  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W220119 10:52:18.744265 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 5.4s
W220119 10:52:18.744274 475 storage/node_liveness.go:463  [n1,hb] failed node liveness heartbeat: aborted during DistSender.Send: context deadline exceeded
W220119 10:52:18.744616 166 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:52:18.744643 1964 storage/replica_write.go:191  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 61.19s for proposing command RequestLease [/Min,/Min).
This range is likely unavailable.
Please contact us with this message to ZNBaseDB technical support 

along with

	https://yourhost:8080/#/reports/range/1

and the following Raft status: {"id":"1","term":14,"vote":"0","commit":3548,"lead":"2","raftState":"StateFollower","applied":3546,"progress":{},"leadtransferee":"0"}
I220119 10:52:18.747013 176 gossip/gossip.go:562  [n1] gossip status (stalled, 3 nodes)
gossip client (2/3 cur/max conns)
  2: ubuntu:23457 (7s: infos 5/17 sent/received, bytes 735B/1907B sent/received)
  3: ubuntu:23458 (5s: infos 5/16 sent/received, bytes 733B/1915B sent/received)
gossip server (0/3 cur/max conns, infos 263/601 sent/received, bytes 174814B/129118B sent/received)
gossip connectivity
  n1 -> n2; n1 -> n3;
W220119 10:52:24.634714 91 gossip/gossip.go:1511  [n1] first range unavailable; resolvers exhausted
I220119 10:52:24.636937 468 server/status/runtime.go:500  [n1] runtime stats: 267 MiB RSS, 234 goroutines, 108 MiB/96 MiB/231 MiB GO alloc/idle/total, 56 MiB/66 MiB CGO alloc/total, 23.6 CGO/sec, 0.3/0.3 %(u/s)time, 6.4 %gc (1x), 1.6 MiB/1.6 MiB (r/w)net
W220119 10:52:36.568200 2531 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:36.584585 2563 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:36.584926 2563 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:36.585335 2492 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23457 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:36.585364 2385 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:36.585460 2439 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:36.585477 2465 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:36.585758 2492 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
W220119 10:52:36.585774 2439 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:52:36.586348 468 server/status/runtime.go:500  [n1] runtime stats: 267 MiB RSS, 234 goroutines, 108 MiB/96 MiB/231 MiB GO alloc/idle/total, 56 MiB/66 MiB CGO alloc/total, 1.2 CGO/sec, 0.1/0.1 %(u/s)time, 0.0 %gc (0x), 598 KiB/598 KiB (r/w)net
W220119 10:52:36.588506 2530 vendor/google.golang.org/grpc/clientconn.go:1304  grpc: addrConn.createTransport failed to connect to {ubuntu:23458 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W220119 10:52:36.588538 2425 storage/raft_transport.go:625  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W220119 10:52:36.588786 2530 vendor/google.golang.org/grpc/clientconn.go:1440  grpc: addrConn.transportMonitor exits due to: context canceled
I220119 10:52:36.588906 846 security/audit/server/audit_server.go:125  [n1] refresh audit server settings
W220119 10:52:36.589045 137 storage/engine/rocksdb.go:2234  batch [8275/941734/12] commit took 17.844315992s (>= warning threshold 500ms)
W220119 10:52:36.589095 475 storage/node_liveness.go:523  [n1,hb] slow heartbeat took 17.8s
W220119 10:52:36.589155 137 storage/store.go:3503  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 22.6s [applied=17, batches=1, state_assertions=0]
W220119 10:52:36.590520 155 storage/store.go:3503  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] handle raft ready: 17.9s [applied=2, batches=2, state_assertions=1]
W220119 10:52:36.591425 151 storage/store.go:3503  [n1,s1,r3/1:/System/{NodeLiveâ€¦-tsd}] handle raft ready: 17.9s [applied=4, batches=1, state_assertions=0]
I220119 10:52:36.591737 2640 gossip/client.go:128  [n1] started gossip client to ubuntu:23457
W220119 10:52:36.591779 150 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 17.9s [applied=3, batches=1, state_assertions=0]
W220119 10:52:37.534747 138 storage/store.go:3503  [n1,s1,r16/1:/Table/2{0-1}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.535056 158 storage/store.go:3503  [n1,s1,r97/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 18.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.535196 142 storage/store.go:3503  [n1,s1,r46/1:/Table/58/1/-92233497859710â€¦] handle raft ready: 18.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.535291 145 storage/store.go:3503  [n1,s1,r78/1:/Table/58/1/-9223349785970â€¦] handle raft ready: 18.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.535430 157 storage/store.go:3503  [n1,s1,r81/1:/Table/58/1/-92233497859705â€¦] handle raft ready: 18.8s [applied=2, batches=1, state_assertions=0]
W220119 10:52:37.535469 159 storage/store.go:3503  [n1,s1,r13/1:/Table/1{7-8}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.535911 143 storage/store.go:3503  [n1,s1,r10/1:/Table/1{4-5}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537033 149 storage/store.go:3503  [n1,s1,r39/1:/Table/57/1/-9223349785974â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537061 144 storage/store.go:3503  [n1,s1,r55/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537033 156 storage/store.go:3503  [n1,s1,r70/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537268 148 storage/store.go:3503  [n1,s1,r66/1:/Table/58/1/-92233497859707â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537280 154 storage/store.go:3503  [n1,s1,r104/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537584 140 storage/store.go:3503  [n1,s1,r103/1:/Table/58/1/-92233497859702â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537652 155 storage/store.go:3503  [n1,s1,r7/1:/Table/1{1-2}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.537664 139 storage/store.go:3503  [n1,s1,r8/1:/Table/1{2-3}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538423 160 storage/store.go:3503  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538471 141 storage/store.go:3503  [n1,s1,r17/1:/Table/2{1-2}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538510 146 storage/store.go:3503  [n1,s1,r36/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538546 147 storage/store.go:3503  [n1,s1,r57/1:/Table/58/1/-92233497859709â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538576 152 storage/store.go:3503  [n1,s1,r107/1:/Table/58/1/-92233497859701â€¦] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.538610 153 storage/store.go:3503  [n1,s1,r20/1:/Table/2{4-5}] handle raft ready: 17.8s [applied=0, batches=0, state_assertions=0]
W220119 10:52:37.539339 137 storage/store.go:3503  [n1,s1,r95/1:/Table/58/1/-92233497859703â€¦] handle raft ready: 1.0s [applied=2, batches=2, state_assertions=1]
W220119 10:52:37.539767 151 storage/store.go:3503  [n1,s1,r43/1:/Table/58/1/-92233497859711â€¦] handle raft ready: 0.9s [applied=2, batches=2, state_assertions=1]
W220119 10:52:37.540107 150 storage/store.go:3503  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.9s [applied=5, batches=2, state_assertions=1]
W220119 10:52:37.543134 173 storage/store_rebalancer.go:226  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I220119 10:52:39.964527 91 gossip/gossip.go:1522  [n1] node has connected to cluster via gossip
W220119 10:52:39.964591 2169 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:52:39.966393 2111 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:52:39.966739 2221 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
W220119 10:52:39.966739 2115 storage/replica_range_lease.go:986  [n1,s1,r1/1:/{Min-System/NodeLâ€¦}] have been waiting 1m0s attempting to acquire lease
